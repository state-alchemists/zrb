[
  {
    "parts": [
      {
        "content": "# Summary of earlier conversation\n<state_snapshot>\n    <overall_goal>\n        Perform comprehensive gap analysis between Zrb hook implementation and Claude Code's actual hook system to achieve 100% compatibility.\n    </overall_goal>\n\n    <active_constraints>\n        - Must maintain 100% compatibility with Claude Code hooks specification\n        - Support all 14 Claude Code hook events and their specific input/output schemas\n        - Ensure proper matcher support for all events (regex-based filtering)\n        - Implement correct JSON output formats for each event type\n        - Support async hooks, prompt hooks, and agent hooks as per Claude Code spec\n        - Handle environment variables like CLAUDE_PROJECT_DIR and CLAUDE_PLUGIN_ROOT\n        - Support hooks in skills, agents, and plugins via frontmatter\n        - Implement proper timeout defaults (600s command, 30s prompt, 60s agent)\n    </active_constraints>\n\n    <key_knowledge>\n        - Claude Code has 14 hook events: SessionStart, UserPromptSubmit, PreToolUse, PermissionRequest, PostToolUse, PostToolUseFailure, Notification, SubagentStart, SubagentStop, Stop, TeammateIdle, TaskCompleted, PreCompact, SessionEnd\n        - Matchers are regex strings that filter when hooks fire; different events match on different fields\n        - UserPromptSubmit and Stop don't support matchers (always fire on every occurrence)\n        - Exit code 2 means blocking error; exit 0 with JSON for structured control\n        - JSON output has universal fields (continue, stopReason, suppressOutput, systemMessage) and event-specific fields\n        - PreToolUse uses hookSpecificOutput with permissionDecision (allow/deny/ask), not top-level decision\n        - PermissionRequest uses hookSpecificOutput with decision.behavior (allow/deny)\n        - Prompt and agent hooks use $ARGUMENTS placeholder for input JSON injection\n        - Async hooks (async: true) only for command hooks, cannot block actions\n        - Hooks can be defined in settings files, plugins, skills, and agent frontmatter\n        - Environment variables: CLAUDE_PROJECT_DIR, CLAUDE_PLUGIN_ROOT, CLAUDE_ENV_FILE (SessionStart only)\n    </key_knowledge>\n\n    <artifact_trail>\n        - Phase 1-3 implementation completed with 14 hook events, matcher evaluation, priority ordering\n        - Phase 4 documentation created with examples and quick start guide\n        - Current implementation supports command, prompt, agent hook types with pydantic_ai integration\n        - Matcher system supports 7 operators but needs regex support for Claude Code compatibility\n        - Priority system implemented (higher priority executes first) - not in Claude Code spec\n        - Dual directory discovery (.zrb/ and .claude/) - Claude Code uses only .claude/\n        - Hook output uses Zrb-specific fields, not Claude Code's standardized JSON format\n    </artifact_trail>\n\n    <file_system_state>\n        - CWD: /root/zrb\n        - READ: src/zrb/llm/hook/schema.py, types.py, executor.py, manager.py\n        - MODIFIED: Various files during Phase 1-4 implementation\n        - CREATED: /root/zrb/examples/hooks/, /root/zrb/docs/, /tmp/ test files\n    </file_system_state>\n\n    <recent_actions>\n        - Examined official Claude Code hooks documentation at code.claude.com/docs/en/hooks\n        - Read current Zrb hook implementation files to understand existing codebase\n        - Identified key differences between Zrb implementation and Claude Code specification\n        - Planning comprehensive gap analysis and compatibility improvements\n    </recent_actions>\n\n    <task_state>\n        1. [DONE] Phase 1-4: Basic hook system implementation\n        2. [IN PROGRESS] Gap Analysis & Compatibility Assessment\n           - [DONE] Research Claude Code official documentation\n           - [DONE] Review current Zrb implementation\n           - [IN PROGRESS] Identify compatibility gaps\n           - [TODO] Create detailed PLAN-POST.md with actionable items\n           - [TODO] Implement compatibility improvements\n        3. [TODO] Final verification and testing\n    </task_state>\n</state_snapshot>\n\n<scratchpad>\nI need to analyze the conversation history to create a structured state snapshot. Let me review what has happened:\n\n1. The AI has been examining the Zrb hook system implementation. It read several files:\n   - `src/zrb/llm/hook/schema.py`: Contains configuration classes for hooks (MatcherConfig, CommandHookConfig, PromptHookConfig, AgentHookConfig, HookConfig)\n   - `src/zrb/llm/hook/types.py`: Defines enums for HookEvent, HookType, and MatcherOperator with Claude Code compatibility\n   - `src/zrb/llm/hook/executor.py`: Thread-safe hook executor with timeout controls and Claude Code compatibility\n   - `src/zrb/llm/hook/manager.py`: Main HookManager class that loads, registers, and executes hooks\n   - `src/zrb/llm/hook/interface.py`: Defines HookContext, HookResult, and HookCallable types\n   - `src/zrb/config/config.py`: Configuration system with hook-related settings (HOOKS_ENABLED, HOOKS_DIRS, etc.)\n\n2. The AI was about to read example hook configurations from the examples/hooks/ directory.\n\nKey discoveries:\n- The system is designed for Claude Code compatibility with specific exit codes (0=success, 2=block)\n- Hook types: COMMAND, PROMPT, AGENT\n- Events include: SESSION_START, USER_PROMPT_SUBMIT, PRE_TOOL_USE, POST_TOOL_USE, etc.\n- Matchers allow conditional hook execution based on context fields\n- Thread-safe execution with timeout controls\n- Configuration loaded from JSON/YAML files in various directories (~/.zrb/hooks/, .zrb/hooks/, etc.)\n\nThe overall goal appears to be understanding and potentially working with the Zrb hook system. The AI is exploring the codebase to understand the structure and capabilities.\n\nRecent actions: Reading multiple source files to understand the hook system architecture.\n\nTask state: The AI is in the middle of exploring the hook system, having just read the core implementation files and about to examine example configurations.\n</scratchpad>\n\n<state_snapshot>\n    <overall_goal>\n        Understand and document the Zrb hook system architecture for Claude Code compatibility.\n    </overall_goal>\n\n    <active_constraints>\n        Must maintain Claude Code compatibility with specific exit codes (0=success, 2=block).\n        Hook system must be thread-safe with timeout controls.\n        Configuration should support JSON/YAML files in standard locations (~/.zrb/hooks/, .zrb/hooks/, etc.).\n    </active_constraints>\n\n    <key_knowledge>\n        - Hook types: COMMAND, PROMPT, AGENT\n        - Hook events: SESSION_START, USER_PROMPT_SUBMIT, PRE_TOOL_USE, POST_TOOL_USE, POST_TOOL_USE_FAILURE, NOTIFICATION, SUBAGENT_START, SUBAGENT_STOP, STOP, TEAMMATE_IDLE, TASK_COMPLETED, PRE_COMPACT, SESSION_END\n        - Matcher operators: EQUALS, NOT_EQUALS, CONTAINS, REGEX, GLOB, STARTS_WITH, ENDS_WITH\n        - Exit code 0 = success, 2 = block (Claude Code standard)\n        - Configuration via CFG.HOOKS_ENABLED, CFG.HOOKS_DIRS, CFG.HOOKS_TIMEOUT\n        - ThreadPoolHookExecutor provides thread-safe execution with default 30s timeout\n        - HookManager auto-scans directories: ~/.claude/hooks.json, ~/.zrb/hooks/, project directories\n    </key_knowledge>\n\n    <artifact_trail>\n        - Examined src/zrb/llm/hook/schema.py: Configuration classes for hooks\n        - Examined src/zrb/llm/hook/types.py: Enum definitions with Claude Code compatibility\n        - Examined src/zrb/llm/hook/executor.py: Thread-safe executor with timeout controls\n        - Examined src/zrb/llm/hook/manager.py: Main HookManager implementation\n        - Examined src/zrb/llm/hook/interface.py: HookContext and HookResult dataclasses\n        - Examined src/zrb/config/config.py: Configuration system with hook settings\n    </artifact_trail>\n\n    <file_system_state>\n        - CWD: Project root (inferred from src/ path)\n        - READ: src/zrb/llm/hook/schema.py, src/zrb/llm/hook/types.py, src/zrb/llm/hook/executor.py, src/zrb/llm/hook/manager.py, src/zrb/llm/hook/interface.py, src/zrb/config/config.py\n        - PENDING READ: examples/hooks/basic-command-hook.json, examples/hooks/security-hook.json, examples/hooks/prompt-review-hook.json, examples/hooks/logging-hook.json\n    </file_system_state>\n\n    <recent_actions>\n        - Read multiple hook system source files to understand architecture\n        - Discovered Claude Code compatibility requirements and implementation details\n        - Identified configuration loading patterns and execution flow\n        - Initiated reading of example hook configurations\n    </recent_actions>\n\n    <task_state>\n        1. [DONE] Read core hook system implementation files\n        2. [IN PROGRESS] Examine example hook configurations to understand usage patterns\n        3. [TODO] Potentially create or modify hook configurations based on understanding\n    </task_state>\n</state_snapshot>\n\n<scratchpad>\nI need to summarize this conversation history into a structured XML snapshot. Let me analyze the provided history:\n\n1. **Tool Result (read_files)**: The AI read several example hook files from `examples/hooks/` directory:\n   - `basic-command-hook.json`: Contains two command hooks for logging session starts and notifying tool use.\n   - `security-hook.json`: Contains security hooks to block dangerous tools and require approval for sensitive operations.\n   - `prompt-review-hook.json`: Contains LLM-based safety review and prompt enhancement hooks.\n   - `logging-hook.json`: Contains audit logging, error monitoring, and session analytics hooks.\n\n2. **AI Tool Call (read_file)**: The AI read the documentation file `docs/hook-system.md` which contains comprehensive documentation about the Zrb Hook System including:\n   - Overview and key features\n   - Architecture and execution flow\n   - Configuration formats and locations\n   - Hook types (command, prompt, agent)\n   - Matcher system with operators\n   - Priority system\n   - Blocking decisions\n   - Environment variables\n   - Events reference\n   - API usage\n   - Best practices\n   - Migration from Claude Code\n   - Troubleshooting\n   - Examples\n\n3. **AI Tool Call (write_file)**: The AI created a comprehensive gap analysis file `PLAN-POST.md` comparing Zrb's hook implementation with Claude Code's official documentation. Key findings:\n   - Identified strengths (event coverage, exit code compatibility, etc.)\n   - Critical gaps in configuration format, matcher system, hook-specific output, async hooks, plugin integration\n   - Created an 8-phase implementation plan to achieve 100% Claude Code compatibility\n   - Includes migration strategy, testing strategy, documentation updates, risk assessment, and timeline\n\n**Overall Goal**: The user wants to analyze and improve Zrb's hook system to achieve 100% compatibility with Claude Code's hook system.\n\n**Key Knowledge**:\n- Zrb Hook System currently has partial compatibility with Claude Code\n- Major format mismatches exist in configuration structure\n- Matcher systems are fundamentally different\n- Hook-specific output formats need standardization\n- Plugin/skill integration is missing\n\n**Artifact Trail**:\n- Created `PLAN-POST.md` with detailed gap analysis and implementation plan\n\n**Recent Actions**:\n- Read example hook files to understand current implementation\n- Read documentation to understand current system capabilities\n- Created comprehensive gap analysis and implementation plan\n\n**Task State**:\n- [DONE] Analyze example hooks and documentation\n- [DONE] Create gap analysis and implementation plan\n- [TODO] Begin implementing Phase 1 (Configuration Format Migration)\n</scratchpad>\n\n<state_snapshot>\n    <overall_goal>\n        Achieve 100% compatibility between Zrb's hook system and Claude Code's official hook system.\n    </overall_goal>\n\n    <active_constraints>\n        Must maintain backward compatibility with existing Zrb hook configurations during migration.\n    </active_constraints>\n\n    <key_knowledge>\n        - Zrb Hook System has 100% basic event coverage with Claude Code but significant format differences\n        - Claude Code uses nested configuration format: hooks.{event}.{matcher}.hooks[]\n        - Zrb uses flat format with events[] and matchers[] arrays\n        - Claude Code matchers are simple regex patterns against specific event fields\n        - Zrb matchers are field-based with 7 operators and dot notation access\n        - Hook-specific output format differs: Claude Code uses hookSpecificOutput with event-specific schemas\n        - Plugin/skill integration and async hooks need enhancement for full compatibility\n    </key_knowledge>\n\n    <artifact_trail>\n        - Created PLAN-POST.md: Comprehensive gap analysis and 8-phase implementation plan for achieving Claude Code compatibility\n    </artifact_trail>\n\n    <file_system_state>\n        - READ: examples/hooks/basic-command-hook.json, security-hook.json, prompt-review-hook.json, logging-hook.json\n        - READ: docs/hook-system.md (detailed Zrb hook system documentation)\n        - CREATED: PLAN-POST.md (gap analysis and implementation plan)\n    </file_system_state>\n\n    <recent_actions>\n        - Read example hook files to understand current Zrb hook implementation patterns\n        - Read hook system documentation to understand current capabilities\n        - Created detailed gap analysis comparing Zrb implementation with Claude Code requirements\n        - Developed 8-phase implementation plan addressing configuration format, matcher system, output standardization, async hooks, plugin integration, and advanced features\n    </recent_actions>\n\n    <task_state>\n        1. [DONE] Analyze example hooks and current documentation\n        2. [DONE] Create comprehensive gap analysis and implementation plan (PLAN-POST.md)\n        3. [TODO] Begin Phase 1 implementation: Configuration Format Migration (support both Zrb and Claude Code formats)\n    </task_state>\n</state_snapshot>\n",
        "timestamp": "2026-02-08T00:26:37.049435Z",
        "part_kind": "user-prompt"
      }
    ],
    "timestamp": "2026-02-08T00:26:37.050719Z",
    "instructions": null,
    "kind": "request",
    "run_id": null,
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "I'll now continue with the gap analysis and compatibility assessment. Based on the conversation history, I need to examine the current Zrb hook implementation more deeply to identify specific compatibility gaps with Claude Code's official specification.\n\nLet me start by reading the current implementation files to understand the exact structure:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_files",
        "args": "{\"paths\": [\"src/zrb/llm/hook/schema.py\", \"src/zrb/llm/hook/types.py\", \"src/zrb/llm/hook/executor.py\", \"src/zrb/llm/hook/manager.py\"]}",
        "tool_call_id": "call_00_hn8zBayBEoTFwCJgJ7sKfojv",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 7739,
      "cache_write_tokens": 0,
      "cache_read_tokens": 4608,
      "output_tokens": 150,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 4608,
        "prompt_cache_miss_tokens": 3131
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:26:38.785925Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:26:37Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "e0598db7-dfac-4a25-9cd6-bd869eacb7bb",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_files",
        "content": {
          "src/zrb/llm/hook/schema.py": "from typing import Any, Dict, List, Optional, Union\n\nfrom zrb.llm.hook.types import HookEvent, HookType, MatcherOperator\n\n\nclass MatcherConfig:\n    def __init__(\n        self,\n        field: str,\n        operator: MatcherOperator,\n        value: Any,\n        case_sensitive: bool = True,\n    ):\n        self.field = field\n        self.operator = operator\n        self.value = value\n        self.case_sensitive = case_sensitive\n\n\nclass CommandHookConfig:\n    def __init__(\n        self,\n        command: str,\n        shell: bool = True,\n        working_dir: Optional[str] = None,\n    ):\n        self.command = command\n        self.shell = shell\n        self.working_dir = working_dir\n\n\nclass PromptHookConfig:\n    def __init__(\n        self,\n        user_prompt_template: str,\n        system_prompt: Optional[str] = None,\n        model: Optional[str] = None,\n        temperature: float = 0.0,\n    ):\n        self.user_prompt_template = user_prompt_template\n        self.system_prompt = system_prompt\n        self.model = model\n        self.temperature = temperature\n\n\nclass AgentHookConfig:\n    def __init__(\n        self,\n        system_prompt: str,\n        tools: List[str] = None,\n        model: Optional[str] = None,\n    ):\n        self.system_prompt = system_prompt\n        self.tools = tools if tools is not None else []\n        self.model = model\n\n\nclass HookConfig:\n    def __init__(\n        self,\n        name: str,\n        events: List[HookEvent],\n        type: HookType,\n        config: Union[CommandHookConfig, PromptHookConfig, AgentHookConfig],\n        description: Optional[str] = None,\n        matchers: List[MatcherConfig] = None,\n        is_async: bool = False,\n        enabled: bool = True,\n        timeout: Optional[int] = None,\n        env: Dict[str, str] = None,\n        priority: int = 0,\n    ):\n        self.name = name\n        self.events = events\n        self.type = type\n        self.config = config\n        self.description = description\n        self.matchers = matchers if matchers is not None else []\n        self.is_async = is_async\n        self.enabled = enabled\n        self.timeout = timeout\n        self.env = env if env is not None else {}\n        self.priority = priority\n",
          "src/zrb/llm/hook/types.py": "from enum import Enum\n\n\nclass HookEvent(str, Enum):\n    \"\"\"All Claude Code hook events for 100% compatibility.\"\"\"\n\n    SESSION_START = \"SessionStart\"\n    USER_PROMPT_SUBMIT = \"UserPromptSubmit\"\n    PRE_TOOL_USE = \"PreToolUse\"\n    PERMISSION_REQUEST = \"PermissionRequest\"\n    POST_TOOL_USE = \"PostToolUse\"\n    POST_TOOL_USE_FAILURE = \"PostToolUseFailure\"\n    NOTIFICATION = \"Notification\"\n    SUBAGENT_START = \"SubagentStart\"\n    SUBAGENT_STOP = \"SubagentStop\"\n    STOP = \"Stop\"\n    TEAMMATE_IDLE = \"TeammateIdle\"\n    TASK_COMPLETED = \"TaskCompleted\"\n    PRE_COMPACT = \"PreCompact\"\n    SESSION_END = \"SessionEnd\"\n\n    # Claude Code compatibility mapping\n    @classmethod\n    def from_claude_string(cls, value: str) -> \"HookEvent\":\n        \"\"\"Convert Claude Code string to HookEvent enum.\"\"\"\n        try:\n            return cls(value)\n        except ValueError:\n            # Handle any case variations\n            upper_value = value.upper()\n            for event in cls:\n                if event.value.upper() == upper_value:\n                    return event\n            raise ValueError(f\"Unknown hook event: {value}\")\n\n\nclass HookType(str, Enum):\n    COMMAND = \"command\"\n    PROMPT = \"prompt\"\n    AGENT = \"agent\"\n\n\nclass MatcherOperator(str, Enum):\n    EQUALS = \"equals\"\n    NOT_EQUALS = \"not_equals\"\n    CONTAINS = \"contains\"\n    REGEX = \"regex\"\n    GLOB = \"glob\"\n    STARTS_WITH = \"starts_with\"\n    ENDS_WITH = \"ends_with\"\n\n    # Claude Code compatibility - regex is the standard\n    @classmethod\n    def from_claude_pattern(cls, pattern: str) -> \"MatcherOperator\":\n        \"\"\"Determine matcher operator from Claude Code pattern.\"\"\"\n        if pattern == \"*\" or pattern == \"\":\n            return cls.GLOB  # Wildcard matches everything\n        elif \"*\" in pattern or \"?\" in pattern or \"[\" in pattern:\n            return cls.GLOB\n        elif pattern.startswith(\"^\") or pattern.endswith(\"$\") or \".*\" in pattern:\n            return cls.REGEX\n        else:\n            return cls.EQUALS\n",
          "src/zrb/llm/hook/executor.py": "\"\"\"\nThread-safe hook executor with timeout controls and proper error handling.\nImplements Claude Code compatible execution patterns.\n\"\"\"\n\nimport asyncio\nimport concurrent.futures\nimport logging\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\nfrom zrb.llm.hook.interface import HookCallable, HookContext, HookResult\nfrom zrb.llm.hook.types import HookEvent\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass HookExecutionResult:\n    \"\"\"Enhanced result with Claude Code compatibility fields.\"\"\"\n\n    success: bool\n    blocked: bool = False\n    message: Optional[str] = None\n    data: Dict[str, Any] = field(default_factory=dict)\n    error: Optional[str] = None\n    exit_code: int = 0\n    decision: Optional[str] = None  # \"block\", \"allow\", \"deny\", \"ask\"\n    reason: Optional[str] = None\n    permission_decision: Optional[str] = None  # \"allow\", \"deny\", \"ask\"\n    permission_decision_reason: Optional[str] = None\n    additional_context: Optional[str] = None\n    updated_input: Optional[Dict[str, Any]] = None\n    system_message: Optional[str] = None\n    continue_execution: bool = True\n    suppress_output: bool = False\n    hook_specific_output: Optional[Dict[str, Any]] = None\n\n\nclass ThreadPoolHookExecutor:\n    \"\"\"\n    Thread-safe executor for hook execution with timeout controls.\n\n    Implements Claude Code compatible execution patterns:\n    - Thread pool with size limits\n    - Timeout controls per hook\n    - Graceful shutdown\n    - Proper error propagation\n    - Exit code handling (0=success, 2=block)\n    \"\"\"\n\n    def __init__(self, max_workers: int = 10, default_timeout: int = 30):\n        self.max_workers = max_workers\n        self.default_timeout = default_timeout\n        self._executor: Optional[ThreadPoolExecutor] = None\n        self._lock = threading.RLock()\n        self._shutdown_event = threading.Event()\n\n    def start(self):\n        \"\"\"Start the thread pool executor.\"\"\"\n        with self._lock:\n            if self._executor is None:\n                self._executor = ThreadPoolExecutor(\n                    max_workers=self.max_workers, thread_name_prefix=\"zrb-hook-\"\n                )\n                self._shutdown_event.clear()\n                logger.debug(f\"Hook executor started with {self.max_workers} workers\")\n\n    def shutdown(self, wait: bool = True):\n        \"\"\"Shutdown the thread pool executor.\"\"\"\n        with self._lock:\n            if self._executor is not None:\n                self._shutdown_event.set()\n                self._executor.shutdown(wait=wait)\n                self._executor = None\n                logger.debug(\"Hook executor shutdown complete\")\n\n    @asynccontextmanager\n    async def execution_context(self):\n        \"\"\"Context manager for hook execution.\"\"\"\n        try:\n            self.start()\n            yield self\n        finally:\n            # Don't shutdown automatically - let the manager handle lifecycle\n            pass\n\n    async def execute_hook(\n        self,\n        hook: HookCallable,\n        context: HookContext,\n        timeout: Optional[int] = None,\n    ) -> HookExecutionResult:\n        \"\"\"\n        Execute a hook with timeout and proper error handling.\n\n        Args:\n            hook: The hook callable to execute\n            context: Hook context with event data\n            timeout: Timeout in seconds (defaults to self.default_timeout)\n\n        Returns:\n            HookExecutionResult with Claude Code compatible fields\n        \"\"\"\n        if self._shutdown_event.is_set():\n            return HookExecutionResult(\n                success=False, error=\"Hook executor is shutting down\", exit_code=1\n            )\n\n        timeout = timeout or self.default_timeout\n\n        try:\n            # Run hook in thread pool with timeout\n            loop = asyncio.get_event_loop()\n            result = await asyncio.wait_for(\n                loop.run_in_executor(\n                    self._executor, self._run_hook_sync, hook, context\n                ),\n                timeout=timeout,\n            )\n            return result\n\n        except asyncio.TimeoutError:\n            logger.warning(f\"Hook execution timed out after {timeout}s\")\n            return HookExecutionResult(\n                success=False,\n                error=f\"Hook execution timed out after {timeout}s\",\n                exit_code=124,  # Standard timeout exit code\n            )\n        except Exception as e:\n            logger.error(f\"Error executing hook: {e}\", exc_info=True)\n            return HookExecutionResult(success=False, error=str(e), exit_code=1)\n\n    def _run_hook_sync(\n        self, hook: HookCallable, context: HookContext\n    ) -> HookExecutionResult:\n        \"\"\"\n        Run hook synchronously in thread pool.\n        This method handles the actual execution and result parsing.\n        \"\"\"\n        try:\n            # Create a new event loop for this thread\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n            # Run the async hook\n            hook_result = loop.run_until_complete(hook(context))\n\n            # Parse result into Claude Code compatible format\n            return self._parse_hook_result(hook_result)\n\n        except Exception as e:\n            logger.error(f\"Error in hook execution: {e}\", exc_info=True)\n            return HookExecutionResult(success=False, error=str(e), exit_code=1)\n        finally:\n            loop.close()\n\n    def _parse_hook_result(self, result: HookResult) -> HookExecutionResult:\n        \"\"\"\n        Parse Zrb HookResult into Claude Code compatible HookExecutionResult.\n\n        Claude Code uses:\n        - exit_code: 0=success, 2=block\n        - decision: \"block\" for blocking decisions\n        - hook_specific_output for event-specific control\n        \"\"\"\n        # Start with basic success/failure\n        exec_result = HookExecutionResult(\n            success=result.success, message=result.output, data=result.data or {}\n        )\n\n        # Check for blocking decisions\n        if result.should_stop:\n            exec_result.blocked = True\n            exec_result.decision = \"block\"\n            exec_result.exit_code = 2\n\n        # Parse modifications for Claude Code compatibility\n        if result.modifications:\n            # Check for Claude Code specific fields\n            if \"decision\" in result.modifications:\n                exec_result.decision = result.modifications[\"decision\"]\n                if exec_result.decision == \"block\":\n                    exec_result.blocked = True\n                    exec_result.exit_code = 2\n\n            if \"reason\" in result.modifications:\n                exec_result.reason = result.modifications[\"reason\"]\n\n            if \"permissionDecision\" in result.modifications:\n                exec_result.permission_decision = result.modifications[\n                    \"permissionDecision\"\n                ]\n\n            if \"permissionDecisionReason\" in result.modifications:\n                exec_result.permission_decision_reason = result.modifications[\n                    \"permissionDecisionReason\"\n                ]\n\n            if \"additionalContext\" in result.modifications:\n                exec_result.additional_context = result.modifications[\n                    \"additionalContext\"\n                ]\n\n            if \"updatedInput\" in result.modifications:\n                exec_result.updated_input = result.modifications[\"updatedInput\"]\n\n            if \"systemMessage\" in result.modifications:\n                exec_result.system_message = result.modifications[\"systemMessage\"]\n\n            if \"continue\" in result.modifications:\n                exec_result.continue_execution = result.modifications[\"continue\"]\n\n            if \"suppressOutput\" in result.modifications:\n                exec_result.suppress_output = result.modifications[\"suppressOutput\"]\n\n            # Check for hookSpecificOutput (Claude Code format)\n            if \"hookSpecificOutput\" in result.modifications:\n                exec_result.hook_specific_output = result.modifications[\n                    \"hookSpecificOutput\"\n                ]\n\n        return exec_result\n\n    def create_claude_compatible_result(\n        self,\n        success: bool = True,\n        blocked: bool = False,\n        message: Optional[str] = None,\n        decision: Optional[str] = None,\n        reason: Optional[str] = None,\n        permission_decision: Optional[str] = None,\n        permission_decision_reason: Optional[str] = None,\n        additional_context: Optional[str] = None,\n        updated_input: Optional[Dict[str, Any]] = None,\n        system_message: Optional[str] = None,\n        continue_execution: bool = True,\n        suppress_output: bool = False,\n        exit_code: int = 0,\n    ) -> HookExecutionResult:\n        \"\"\"\n        Create a Claude Code compatible hook result.\n\n        This is a helper for hook implementations to ensure compatibility.\n        \"\"\"\n        return HookExecutionResult(\n            success=success,\n            blocked=blocked,\n            message=message,\n            decision=decision,\n            reason=reason,\n            permission_decision=permission_decision,\n            permission_decision_reason=permission_decision_reason,\n            additional_context=additional_context,\n            updated_input=updated_input,\n            system_message=system_message,\n            continue_execution=continue_execution,\n            suppress_output=suppress_output,\n            exit_code=exit_code,\n        )\n\n\n# Singleton instance\n_hook_executor: Optional[ThreadPoolHookExecutor] = None\n\n\ndef get_hook_executor() -> ThreadPoolHookExecutor:\n    \"\"\"Get or create the singleton hook executor.\"\"\"\n    global _hook_executor\n    if _hook_executor is None:\n        _hook_executor = ThreadPoolHookExecutor()\n        _hook_executor.start()\n    return _hook_executor\n\n\ndef shutdown_hook_executor(wait: bool = True):\n    \"\"\"Shutdown the singleton hook executor.\"\"\"\n    global _hook_executor\n    if _hook_executor is not None:\n        _hook_executor.shutdown(wait=wait)\n        _hook_executor = None\n",
          "src/zrb/llm/hook/manager.py": "import asyncio\nimport json\nimport logging\nimport os\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\n\nimport yaml\n\nfrom zrb.config.config import CFG\nfrom zrb.llm.hook.executor import (\n    HookExecutionResult,\n    ThreadPoolHookExecutor,\n    get_hook_executor,\n)\nfrom zrb.llm.hook.interface import HookCallable, HookContext, HookResult\nfrom zrb.llm.hook.schema import (\n    AgentHookConfig,\n    CommandHookConfig,\n    HookConfig,\n    MatcherConfig,\n    PromptHookConfig,\n)\nfrom zrb.llm.hook.types import HookEvent, HookType, MatcherOperator\n\nlogger = logging.getLogger(__name__)\n\n\nclass HookManager:\n    def __init__(\n        self,\n        auto_load: bool = True,\n        scan_dirs: Optional[List[Union[str, Path]]] = None,\n    ):\n        self._hooks: Dict[HookEvent, List[HookCallable]] = defaultdict(list)\n        self._global_hooks: List[HookCallable] = []\n        self._executor: ThreadPoolHookExecutor = get_hook_executor()\n        self._hook_configs: Dict[str, HookConfig] = {}  # name -> config for debugging\n        self._hook_to_config: Dict[HookCallable, HookConfig] = {}  # hook -> config mapping\n        if auto_load:\n            self.scan(scan_dirs)\n\n    def _evaluate_matchers(self, matchers: List[MatcherConfig], context: HookContext) -> bool:\n        \"\"\"\n        Evaluate all matchers against the given context.\n        Returns True if ALL matchers pass, False otherwise.\n        \n        Matchers can access fields in the context using dot notation.\n        For example: \"metadata.project\" or \"event_data.file_path\"\n        \"\"\"\n        if not matchers:\n            return True  # No matchers means always match\n            \n        for matcher in matchers:\n            # Get the value from context using dot notation\n            value = self._get_field_value(context, matcher.field)\n            \n            # Apply case sensitivity if needed\n            if not matcher.case_sensitive and isinstance(value, str):\n                value = value.lower()\n                matcher_value = matcher.value.lower() if isinstance(matcher.value, str) else matcher.value\n            else:\n                matcher_value = matcher.value\n            \n            # Evaluate based on operator\n            if matcher.operator == MatcherOperator.EQUALS:\n                if value != matcher_value:\n                    return False\n                    \n            elif matcher.operator == MatcherOperator.NOT_EQUALS:\n                if value == matcher_value:\n                    return False\n                    \n            elif matcher.operator == MatcherOperator.CONTAINS:\n                if not isinstance(value, str) or not isinstance(matcher_value, str):\n                    return False\n                if matcher_value not in value:\n                    return False\n                    \n            elif matcher.operator == MatcherOperator.STARTS_WITH:\n                if not isinstance(value, str) or not isinstance(matcher_value, str):\n                    return False\n                if not value.startswith(matcher_value):\n                    return False\n                    \n            elif matcher.operator == MatcherOperator.ENDS_WITH:\n                if not isinstance(value, str) or not isinstance(matcher_value, str):\n                    return False\n                if not value.endswith(matcher_value):\n                    return False\n                    \n            elif matcher.operator == MatcherOperator.REGEX:\n                import re\n                if not isinstance(value, str) or not isinstance(matcher_value, str):\n                    return False\n                try:\n                    if not re.search(matcher_value, value):\n                        return False\n                except re.error:\n                    logger.warning(f\"Invalid regex pattern in matcher: {matcher_value}\")\n                    return False\n                    \n            elif matcher.operator == MatcherOperator.GLOB:\n                import fnmatch\n                if not isinstance(value, str) or not isinstance(matcher_value, str):\n                    return False\n                if not fnmatch.fnmatch(value, matcher_value):\n                    return False\n                    \n            else:\n                logger.warning(f\"Unknown matcher operator: {matcher.operator}\")\n                return False\n        \n        return True\n\n    def _get_field_value(self, context: HookContext, field_path: str) -> Any:\n        \"\"\"\n        Get a value from context using dot notation.\n        Supports nested access like \"metadata.project.name\"\n        \"\"\"\n        parts = field_path.split('.')\n        current = context\n        \n        for part in parts:\n            if hasattr(current, part):\n                current = getattr(current, part)\n            elif isinstance(current, dict) and part in current:\n                current = current[part]\n            else:\n                # Try to access via getattr with default\n                try:\n                    current = getattr(current, part)\n                except AttributeError:\n                    # Return None if field doesn't exist\n                    return None\n        \n        return current\n\n    def register(self, hook: HookCallable, events: Optional[List[HookEvent]] = None, config: Optional[HookConfig] = None):\n        \"\"\"\n        Register a hook.\n        If events is None or empty, the hook is treated as a global hook (runs on all events).\n        Otherwise, it is registered for the specific events.\n        \"\"\"\n        if config:\n            self._hook_to_config[hook] = config\n        \n        if not events:\n            self._global_hooks.append(hook)\n        else:\n            for event in events:\n                self._hooks[event].append(hook)\n\n    async def execute_hooks(\n        self,\n        event: HookEvent,\n        event_data: Any,\n        session_id: Optional[str] = None,\n        metadata: Dict[str, Any] = None,\n        cwd: Optional[str] = None,\n        transcript_path: Optional[str] = None,\n        permission_mode: str = \"default\",\n        **kwargs,\n    ) -> List[HookExecutionResult]:\n        \"\"\"\n        Execute all hooks registered for the given event with thread safety.\n        Returns a list of HookExecutionResult objects with Claude Code compatibility.\n        \"\"\"\n        if metadata is None:\n            metadata = {}\n\n        # Create enhanced context with Claude Code fields\n        context = HookContext(\n            event=event,\n            event_data=event_data,\n            session_id=session_id,\n            metadata=metadata,\n            cwd=cwd or os.getcwd(),\n            transcript_path=transcript_path,\n            permission_mode=permission_mode,\n            hook_event_name=event.value,\n        )\n\n        # Populate event-specific fields from kwargs\n        for key, value in kwargs.items():\n            if hasattr(context, key):\n                setattr(context, key, value)\n\n        results: List[HookExecutionResult] = []\n\n        # Combine global hooks and event-specific hooks\n        hooks_to_run = self._global_hooks + self._hooks[event]\n\n        if not hooks_to_run:\n            return results\n\n        # Sort hooks by priority (higher priority first)\n        # Create a default config for hooks without config (e.g., manually registered)\n        default_config = HookConfig(\n            name=\"default\", \n            events=[], \n            type=HookType.COMMAND, \n            config=CommandHookConfig(command=\"\"),\n            priority=0\n        )\n        hooks_to_run = sorted(\n            hooks_to_run,\n            key=lambda h: self._hook_to_config.get(h, default_config).priority,\n            reverse=True  # Higher priority first\n        )\n\n        # Execute hooks with thread pool and timeout controls\n        tasks = []\n        for hook in hooks_to_run:\n            # Get timeout from config if available\n            timeout = None\n            if hook in self._hook_to_config:\n                config = self._hook_to_config[hook]\n                timeout = config.timeout\n\n            task = self._executor.execute_hook(hook, context, timeout=timeout)\n            tasks.append(task)\n\n        # Wait for all hooks to complete\n        hook_results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        for i, result in enumerate(hook_results):\n            if isinstance(result, Exception):\n                logger.error(\n                    f\"Error executing hook {i} for event {event}: {result}\",\n                    exc_info=True,\n                )\n                results.append(\n                    HookExecutionResult(success=False, error=str(result), exit_code=1)\n                )\n            else:\n                results.append(result)\n\n                # Check for blocking decisions (exit code 2)\n                if result.blocked or result.exit_code == 2:\n                    logger.info(\n                        f\"Hook blocked execution. Stopping further hooks for event {event}.\"\n                    )\n                    # Return only results up to this point\n                    return results[: i + 1]\n\n                # Check for continue=false\n                if not result.continue_execution:\n                    logger.info(\n                        f\"Hook requested stop of all processing for event {event}.\"\n                    )\n                    return results[: i + 1]\n\n        return results\n\n    async def execute_hooks_simple(\n        self,\n        event: HookEvent,\n        event_data: Any,\n        session_id: Optional[str] = None,\n        metadata: Dict[str, Any] = None,\n    ) -> List[HookResult]:\n        \"\"\"\n        Backward compatibility method that returns old HookResult format.\n        \"\"\"\n        exec_results = await self.execute_hooks(\n            event=event,\n            event_data=event_data,\n            session_id=session_id,\n            metadata=metadata,\n        )\n\n        # Convert to old format\n        results: List[HookResult] = []\n        for exec_result in exec_results:\n            modifications = {}\n            if exec_result.decision:\n                modifications[\"decision\"] = exec_result.decision\n            if exec_result.reason:\n                modifications[\"reason\"] = exec_result.reason\n            if exec_result.permission_decision:\n                modifications[\"permissionDecision\"] = exec_result.permission_decision\n            if exec_result.permission_decision_reason:\n                modifications[\"permissionDecisionReason\"] = (\n                    exec_result.permission_decision_reason\n                )\n            if exec_result.additional_context:\n                modifications[\"additionalContext\"] = exec_result.additional_context\n            if exec_result.updated_input:\n                modifications[\"updatedInput\"] = exec_result.updated_input\n            if exec_result.system_message:\n                modifications[\"systemMessage\"] = exec_result.system_message\n            if not exec_result.continue_execution:\n                modifications[\"continue\"] = False\n            if exec_result.suppress_output:\n                modifications[\"suppressOutput\"] = True\n            if exec_result.hook_specific_output:\n                modifications[\"hookSpecificOutput\"] = exec_result.hook_specific_output\n\n            result = HookResult(\n                success=exec_result.success,\n                output=exec_result.message or exec_result.error,\n                data=exec_result.data,\n                modifications=modifications,\n                should_stop=exec_result.blocked or not exec_result.continue_execution,\n            )\n            results.append(result)\n\n        return results\n\n    def scan(self, search_dirs: Optional[List[Union[str, Path]]] = None):\n        \"\"\"\n        Scan for hooks in default locations and provided directories.\n        \"\"\"\n        target_search_dirs = search_dirs\n        if target_search_dirs is None:\n            target_search_dirs = self.get_search_directories()\n\n        for search_dir in target_search_dirs:\n            self._load_from_path(search_dir)\n\n    def get_search_directories(self) -> List[Union[str, Path]]:\n        search_dirs: List[Union[str, Path]] = []\n        zrb_dir_name = f\".{CFG.ROOT_GROUP_NAME}\"\n\n        # 1. User global config (~/.zrb/hooks.json and ~/.zrb/hooks/)\n        try:\n            home = Path.home()\n            # Claude style\n            global_claude_hooks_file = home / \".claude\" / \"hooks.json\"\n            if global_claude_hooks_file.exists() and global_claude_hooks_file.is_file():\n                search_dirs.append(global_claude_hooks_file)\n\n            global_claude_hooks_dir = home / \".claude\" / \"hooks\"\n            if global_claude_hooks_dir.exists() and global_claude_hooks_dir.is_dir():\n                search_dirs.append(global_claude_hooks_dir)\n\n            # Zrb style\n            global_zrb_hooks_file = home / zrb_dir_name / \"hooks.json\"\n            if global_zrb_hooks_file.exists() and global_zrb_hooks_file.is_file():\n                search_dirs.append(global_zrb_hooks_file)\n\n            global_zrb_hooks_dir = home / zrb_dir_name / \"hooks\"\n            if global_zrb_hooks_dir.exists() and global_zrb_hooks_dir.is_dir():\n                search_dirs.append(global_zrb_hooks_dir)\n        except Exception:\n            pass\n\n        # 2. Project directories (.zrb/hooks.json and .zrb/hooks/)\n        try:\n            cwd = Path.cwd()\n            project_dirs = list(cwd.parents)[::-1] + [cwd]\n            for project_dir in project_dirs:\n                # Claude style\n                local_claude_hooks_file = project_dir / \".claude\" / \"hooks.json\"\n                if (\n                    local_claude_hooks_file.exists()\n                    and local_claude_hooks_file.is_file()\n                ):\n                    search_dirs.append(local_claude_hooks_file)\n\n                local_claude_hooks_dir = project_dir / \".claude\" / \"hooks\"\n                if local_claude_hooks_dir.exists() and local_claude_hooks_dir.is_dir():\n                    search_dirs.append(local_claude_hooks_dir)\n\n                # Zrb style\n                local_zrb_hooks_file = project_dir / zrb_dir_name / \"hooks.json\"\n                if local_zrb_hooks_file.exists() and local_zrb_hooks_file.is_file():\n                    search_dirs.append(local_zrb_hooks_file)\n\n                local_zrb_hooks_dir = project_dir / zrb_dir_name / \"hooks\"\n                if local_zrb_hooks_dir.exists() and local_zrb_hooks_dir.is_dir():\n                    search_dirs.append(local_zrb_hooks_dir)\n        except Exception:\n            pass\n\n        # 3. Custom directories from CFG\n        for d in CFG.HOOKS_DIRS:\n            search_dirs.append(Path(d))\n\n        return search_dirs\n\n    def _load_from_path(self, path: Union[str, Path]):\n        path = Path(path)\n        if not path.exists():\n            return\n\n        if path.is_file():\n            if path.suffix in [\".json\", \".yaml\", \".yml\"]:\n                self._load_file(path)\n        elif path.is_dir():\n            for root, _, files in os.walk(path):\n                for file in files:\n                    file_path = Path(root) / file\n                    if file_path.suffix in [\".json\", \".yaml\", \".yml\"]:\n                        self._load_file(file_path)\n\n    def _load_file(self, file_path: Path):\n        logger.debug(f\"Loading hooks from {file_path}\")\n        try:\n            with open(file_path, \"r\") as f:\n                if file_path.suffix == \".json\":\n                    data = json.load(f)\n                else:\n                    data = yaml.safe_load(f)\n\n            if isinstance(data, list):\n                for item in data:\n                    self._parse_and_register(item, str(file_path))\n            elif isinstance(data, dict):\n                self._parse_and_register(data, str(file_path))\n\n        except Exception as e:\n            logger.error(f\"Failed to load hooks from {file_path}: {e}\")\n\n    def _parse_and_register(self, data: dict, source: str):\n        try:\n            config = self._create_hook_config(data)\n            if not config.enabled:\n                return\n\n            hook_callable = self._hydrate_hook(config)\n            self.register(hook_callable, config.events, config)\n            logger.info(f\"Registered hook '{config.name}' from {source}\")\n        except Exception as e:\n            logger.error(f\"Error registering hook from {source}: {e}\", exc_info=True)\n\n    def _create_hook_config(self, data: dict) -> HookConfig:\n        # Manual parsing because we are not using Pydantic BaseModel\n        name = data[\"name\"]\n        events = [HookEvent(e) for e in data[\"events\"]]\n        hook_type = HookType(data[\"type\"])\n\n        raw_config = data[\"config\"]\n        if hook_type == HookType.COMMAND:\n            config = CommandHookConfig(\n                command=raw_config[\"command\"],\n                shell=raw_config.get(\"shell\", True),\n                working_dir=raw_config.get(\"working_dir\"),\n            )\n        elif hook_type == HookType.PROMPT:\n            config = PromptHookConfig(\n                user_prompt_template=raw_config[\"user_prompt_template\"],\n                system_prompt=raw_config.get(\"system_prompt\"),\n                model=raw_config.get(\"model\"),\n                temperature=raw_config.get(\"temperature\", 0.0),\n            )\n        elif hook_type == HookType.AGENT:\n            config = AgentHookConfig(\n                system_prompt=raw_config[\"system_prompt\"],\n                tools=raw_config.get(\"tools\"),\n                model=raw_config.get(\"model\"),\n            )\n        else:\n            raise ValueError(f\"Unknown hook type: {hook_type}\")\n\n        matchers = []\n        for m in data.get(\"matchers\", []):\n            matchers.append(\n                MatcherConfig(\n                    field=m[\"field\"],\n                    operator=MatcherOperator(m[\"operator\"]),\n                    value=m[\"value\"],\n                    case_sensitive=m.get(\"case_sensitive\", True),\n                )\n            )\n\n        return HookConfig(\n            name=name,\n            events=events,\n            type=hook_type,\n            config=config,\n            description=data.get(\"description\"),\n            matchers=matchers,\n            is_async=data.get(\"async\", False),\n            enabled=data.get(\"enabled\", True),\n            timeout=data.get(\"timeout\"),\n            env=data.get(\"env\"),\n            priority=data.get(\"priority\", 0),\n        )\n\n    def _hydrate_hook(self, config: HookConfig) -> HookCallable:\n        \"\"\"\n        Convert HookConfig into a HookCallable using appropriate executor.\n        Wraps the actual hook with matcher evaluation.\n        \"\"\"\n        # Create the actual hook callable\n        if config.type == HookType.COMMAND:\n            inner_hook = self._create_command_hook(config.config)\n        elif config.type == HookType.PROMPT:\n            inner_hook = self._create_prompt_hook(config.config)\n        elif config.type == HookType.AGENT:\n            inner_hook = self._create_agent_hook(config.config)\n        else:\n            async def placeholder_hook(context: HookContext) -> HookResult:\n                logger.warning(\n                    f\"Executing placeholder for hook '{config.name}' (Type: {config.type}).\"\n                )\n                return HookResult(success=True, output=f\"Placeholder for {config.name}\")\n            inner_hook = placeholder_hook\n\n        # Store config for debugging and timeout lookup\n        self._hook_configs[config.name] = config\n\n        # Create wrapper that evaluates matchers\n        async def hook_with_matchers(context: HookContext) -> HookResult:\n            # Evaluate matchers first\n            if not self._evaluate_matchers(config.matchers, context):\n                logger.debug(\n                    f\"Hook '{config.name}' skipped due to matcher evaluation failure\"\n                )\n                # Return a neutral result (not an error, just didn't run)\n                return HookResult(success=True, output=\"Skipped due to matchers\")\n            \n            # Execute the actual hook\n            return await inner_hook(context)\n\n        return hook_with_matchers\n\n    def _create_command_hook(self, config: CommandHookConfig) -> HookCallable:\n        async def command_hook(context: HookContext) -> HookResult:\n            import subprocess\n\n            # Prepare environment with Claude Code context variables\n            env = os.environ.copy()\n            \n            # Inject Claude Code context variables for hook scripts\n            env[\"CLAUDE_HOOK_EVENT\"] = str(context.event.value)\n            env[\"CLAUDE_HOOK_EVENT_NAME\"] = context.hook_event_name or str(context.event.value)\n            env[\"CLAUDE_CWD\"] = context.cwd or \"\"\n            env[\"CLAUDE_TRANSCRIPT_PATH\"] = context.transcript_path or \"\"\n            env[\"CLAUDE_PERMISSION_MODE\"] = context.permission_mode\n            \n            # Inject event-specific data as JSON\n            import json as json_module\n            try:\n                # Try to serialize event_data, fall back to string representation\n                if context.event_data is not None:\n                    env[\"CLAUDE_EVENT_DATA\"] = json_module.dumps(context.event_data)\n                else:\n                    env[\"CLAUDE_EVENT_DATA\"] = \"null\"\n            except (TypeError, ValueError):\n                # If not JSON serializable, use string representation\n                env[\"CLAUDE_EVENT_DATA\"] = str(context.event_data)\n            \n            # Add context fields to environment\n            for field in [\"tool_name\", \"tool_input\", \"prompt\", \"message\", \"title\", \n                         \"notification_type\", \"agent_id\", \"teammate_name\", \"task_id\"]:\n                value = getattr(context, field, None)\n                if value is not None:\n                    if isinstance(value, dict):\n                        env[f\"CLAUDE_{field.upper()}\"] = json_module.dumps(value)\n                    else:\n                        env[f\"CLAUDE_{field.upper()}\"] = str(value)\n\n            try:\n                # Run command with timeout\n                process = await asyncio.create_subprocess_shell(\n                    config.command,\n                    stdout=asyncio.subprocess.PIPE,\n                    stderr=asyncio.subprocess.PIPE,\n                    cwd=config.working_dir or context.cwd,\n                    env=env,\n                )\n                stdout, stderr = await process.communicate()\n\n                output = stdout.decode().strip()\n                stderr_output = stderr.decode().strip()\n                \n                # Claude Code compatibility: exit code 2 means block, 0 means success\n                # Other non-zero exit codes are errors\n                exit_code = process.returncode\n                \n                if exit_code == 2:\n                    # Blocking decision - parse output for reason\n                    modifications = {}\n                    reason = \"Blocked by hook\"\n                    \n                    try:\n                        data = json_module.loads(output)\n                        if isinstance(data, dict):\n                            # Claude Code format: {\"decision\": \"block\", \"reason\": \"...\", ...}\n                            modifications = data\n                            if \"reason\" in data:\n                                reason = data[\"reason\"]\n                    except Exception:\n                        # If not JSON, use output as reason\n                        if output:\n                            reason = output\n                    \n                    # Merge provided modifications with blocking modifications\n                    blocking_modifications = {\n                        \"decision\": \"block\",\n                        \"reason\": reason,\n                        \"exit_code\": 2\n                    }\n                    blocking_modifications.update(modifications)\n                    return HookResult(\n                        success=False, \n                        output=output,  # Include output for logging/debugging\n                        should_stop=True, \n                        modifications=blocking_modifications\n                    )\n                \n                elif exit_code == 0:\n                    # Success - parse output for modifications\n                    modifications = {}\n                    try:\n                        data = json_module.loads(output)\n                        if isinstance(data, dict):\n                            modifications = data\n                    except Exception:\n                        # Not JSON, treat as plain output\n                        pass\n                    \n                    return HookResult(\n                        success=True, \n                        output=output, \n                        modifications=modifications\n                    )\n                else:\n                    # Error case\n                    error_msg = f\"Command failed with exit code {exit_code}\"\n                    if stderr_output:\n                        error_msg += f\": {stderr_output}\"\n                    elif output:\n                        error_msg += f\": {output}\"\n                    \n                    logger.error(f\"Command hook failed: {error_msg}\")\n                    return HookResult(success=False, output=error_msg)\n                    \n            except Exception as e:\n                logger.error(f\"Error executing command hook: {e}\")\n                return HookResult(success=False, output=str(e))\n\n        return command_hook\n\n    def _create_prompt_hook(self, config: PromptHookConfig) -> HookCallable:\n        async def prompt_hook(context: HookContext) -> HookResult:\n            \"\"\"\n            Execute a prompt hook using the LLM system.\n            This runs an LLM with the given prompt template and returns the result.\n            \"\"\"\n            try:\n                # Import here to avoid circular imports\n                from pydantic_ai import Agent\n                from pydantic_ai.models.openai import OpenAIModel\n                \n                # Get LLM configuration\n                model_name = config.model or CFG.LLM_MODEL\n                if not model_name:\n                    logger.error(\"No LLM model configured for prompt hook\")\n                    return HookResult(\n                        success=False, \n                        output=\"No LLM model configured\"\n                    )\n                \n                # Parse model name (format: provider:model)\n                if \":\" in model_name:\n                    provider, model = model_name.split(\":\", 1)\n                else:\n                    provider = \"openai\"\n                    model = model_name\n                \n                # Create model based on provider\n                if provider == \"openai\":\n                    llm_model = OpenAIModel(model)\n                else:\n                    # For other providers, we'd need to handle them\n                    # For now, use OpenAI as default\n                    logger.warning(f\"Provider {provider} not fully supported, using OpenAI\")\n                    llm_model = OpenAIModel(model)\n                \n                # Create agent with the prompt\n                agent = Agent(\n                    model=llm_model,\n                    system_prompt=config.system_prompt or \"\",\n                    deps_type=dict,\n                )\n                \n                # Format user prompt template with context\n                # Simple template substitution using context fields\n                user_prompt = config.user_prompt_template\n                for field_name in dir(context):\n                    if not field_name.startswith(\"_\"):\n                        field_value = getattr(context, field_name)\n                        if isinstance(field_value, (str, int, float, bool)):\n                            placeholder = f\"{{{{{field_name}}}}}\"\n                            if placeholder in user_prompt:\n                                user_prompt = user_prompt.replace(\n                                    placeholder, str(field_value)\n                                )\n                \n                # Run the agent\n                result = await agent.run(user_prompt, deps={})\n                \n                # Parse the result for modifications\n                modifications = {}\n                try:\n                    # Try to parse as JSON if it looks like JSON\n                    import json\n                    output_text = str(result.output)\n                    if output_text.strip().startswith(\"{\") and output_text.strip().endswith(\"}\"):\n                        parsed = json.loads(output_text)\n                        if isinstance(parsed, dict):\n                            modifications = parsed\n                except Exception:\n                    # Not JSON, use as plain output\n                    pass\n                \n                return HookResult(\n                    success=True,\n                    output=str(result.output),\n                    modifications=modifications\n                )\n                \n            except Exception as e:\n                logger.error(f\"Error executing prompt hook: {e}\", exc_info=True)\n                return HookResult(success=False, output=str(e))\n\n        return prompt_hook\n\n    def _create_agent_hook(self, config: AgentHookConfig) -> HookCallable:\n        async def agent_hook(context: HookContext) -> HookResult:\n            \"\"\"\n            Execute an agent hook with tools.\n            This creates an agent with the given system prompt and tools.\n            \"\"\"\n            try:\n                # Import here to avoid circular imports\n                from pydantic_ai import Agent\n                from pydantic_ai.models.openai import OpenAIModel\n                \n                # Get LLM configuration\n                model_name = config.model or CFG.LLM_MODEL\n                if not model_name:\n                    logger.error(\"No LLM model configured for agent hook\")\n                    return HookResult(\n                        success=False, \n                        output=\"No LLM model configured\"\n                    )\n                \n                # Parse model name (format: provider:model)\n                if \":\" in model_name:\n                    provider, model = model_name.split(\":\", 1)\n                else:\n                    provider = \"openai\"\n                    model = model_name\n                \n                # Create model based on provider\n                if provider == \"openai\":\n                    llm_model = OpenAIModel(model)\n                else:\n                    # For other providers, we'd need to handle them\n                    # For now, use OpenAI as default\n                    logger.warning(f\"Provider {provider} not fully supported, using OpenAI\")\n                    llm_model = OpenAIModel(model)\n                \n                # Create agent with system prompt\n                agent = Agent(\n                    model=llm_model,\n                    system_prompt=config.system_prompt,\n                    deps_type=dict,\n                )\n                \n                # TODO: Add tools from config.tools\n                # For now, run without tools\n                \n                # Create a prompt from context\n                # Use event_data or other context fields as input\n                user_input = \"\"\n                if context.event_data:\n                    if isinstance(context.event_data, dict):\n                        user_input = str(context.event_data)\n                    else:\n                        user_input = str(context.event_data)\n                elif hasattr(context, 'prompt') and context.prompt:\n                    user_input = context.prompt\n                else:\n                    user_input = f\"Hook event: {context.event.value}\"\n                \n                # Run the agent\n                result = await agent.run(user_input, deps={})\n                \n                # Parse the result for modifications\n                modifications = {}\n                try:\n                    # Try to parse as JSON if it looks like JSON\n                    import json\n                    output_text = str(result.output)\n                    if output_text.strip().startswith(\"{\") and output_text.strip().endswith(\"}\"):\n                        parsed = json.loads(output_text)\n                        if isinstance(parsed, dict):\n                            modifications = parsed\n                except Exception:\n                    # Not JSON, use as plain output\n                    pass\n                \n                return HookResult(\n                    success=True,\n                    output=str(result.output),\n                    modifications=modifications\n                )\n                \n            except Exception as e:\n                logger.error(f\"Error executing agent hook: {e}\", exc_info=True)\n                return HookResult(success=False, output=str(e))\n\n        return agent_hook\n\n\nhook_manager = HookManager(auto_load=CFG.HOOKS_ENABLED, scan_dirs=CFG.HOOKS_DIRS)\n"
        },
        "tool_call_id": "call_00_hn8zBayBEoTFwCJgJ7sKfojv",
        "metadata": null,
        "timestamp": "2026-02-08T00:30:07.647669Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:30:07.902327Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me read the interface file to understand the data structures:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"src/zrb/llm/hook/interface.py\"}",
        "tool_call_id": "call_00_ThbWUxA88oZHYp7oeUwWqDWT",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 23053,
      "cache_write_tokens": 0,
      "cache_read_tokens": 8448,
      "output_tokens": 65,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 8448,
        "prompt_cache_miss_tokens": 14605
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:30:12.749365Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:30:09Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "87f96dc5-ab43-4d45-a1f6-5da51dbfa390",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "from dataclasses import dataclass, field\nfrom typing import Any, Awaitable, Callable, Dict, List, Optional, Union\n\nfrom zrb.llm.hook.types import HookEvent\n\n\n@dataclass\nclass HookContext:\n    \"\"\"Claude Code compatible hook context.\"\"\"\n\n    event: HookEvent\n    event_data: Any\n    session_id: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    # Claude Code standard fields\n    transcript_path: Optional[str] = None\n    cwd: Optional[str] = None\n    permission_mode: str = \"default\"\n    hook_event_name: Optional[str] = None  # For compatibility with Claude Code JSON\n\n    # Event-specific fields (populated based on event type)\n    prompt: Optional[str] = None  # UserPromptSubmit\n    tool_name: Optional[str] = None  # PreToolUse, PostToolUse, etc.\n    tool_input: Optional[Dict[str, Any]] = None\n    tool_response: Optional[Dict[str, Any]] = None\n    tool_use_id: Optional[str] = None\n    error: Optional[str] = None  # PostToolUseFailure\n    is_interrupt: Optional[bool] = None\n    message: Optional[str] = None  # Notification\n    title: Optional[str] = None\n    notification_type: Optional[str] = None\n    agent_id: Optional[str] = None  # SubagentStart/Stop\n    agent_type: Optional[str] = None\n    agent_transcript_path: Optional[str] = None\n    stop_hook_active: Optional[bool] = None  # Stop\n    teammate_name: Optional[str] = None  # TeammateIdle\n    team_name: Optional[str] = None\n    task_id: Optional[str] = None  # TaskCompleted\n    task_subject: Optional[str] = None\n    task_description: Optional[str] = None\n    trigger: Optional[str] = None  # PreCompact\n    custom_instructions: Optional[str] = None\n    reason: Optional[str] = None  # SessionEnd\n    source: Optional[str] = None  # SessionStart\n    model: Optional[str] = None\n    permission_suggestions: Optional[List[Dict[str, Any]]] = None  # PermissionRequest\n\n    def to_claude_json(self) -> Dict[str, Any]:\n        \"\"\"Convert to Claude Code compatible JSON format.\"\"\"\n        base = {\n            \"session_id\": self.session_id,\n            \"transcript_path\": self.transcript_path,\n            \"cwd\": self.cwd,\n            \"permission_mode\": self.permission_mode,\n            \"hook_event_name\": self.hook_event_name or self.event.value,\n        }\n\n        # Add event-specific fields\n        if self.prompt is not None:\n            base[\"prompt\"] = self.prompt\n\n        if self.tool_name is not None:\n            base[\"tool_name\"] = self.tool_name\n\n        if self.tool_input is not None:\n            base[\"tool_input\"] = self.tool_input\n\n        if self.tool_response is not None:\n            base[\"tool_response\"] = self.tool_response\n\n        if self.tool_use_id is not None:\n            base[\"tool_use_id\"] = self.tool_use_id\n\n        if self.error is not None:\n            base[\"error\"] = self.error\n\n        if self.is_interrupt is not None:\n            base[\"is_interrupt\"] = self.is_interrupt\n\n        if self.message is not None:\n            base[\"message\"] = self.message\n\n        if self.title is not None:\n            base[\"title\"] = self.title\n\n        if self.notification_type is not None:\n            base[\"notification_type\"] = self.notification_type\n\n        if self.agent_id is not None:\n            base[\"agent_id\"] = self.agent_id\n\n        if self.agent_type is not None:\n            base[\"agent_type\"] = self.agent_type\n\n        if self.agent_transcript_path is not None:\n            base[\"agent_transcript_path\"] = self.agent_transcript_path\n\n        if self.stop_hook_active is not None:\n            base[\"stop_hook_active\"] = self.stop_hook_active\n\n        if self.teammate_name is not None:\n            base[\"teammate_name\"] = self.teammate_name\n\n        if self.team_name is not None:\n            base[\"team_name\"] = self.team_name\n\n        if self.task_id is not None:\n            base[\"task_id\"] = self.task_id\n\n        if self.task_subject is not None:\n            base[\"task_subject\"] = self.task_subject\n\n        if self.task_description is not None:\n            base[\"task_description\"] = self.task_description\n\n        if self.trigger is not None:\n            base[\"trigger\"] = self.trigger\n\n        if self.custom_instructions is not None:\n            base[\"custom_instructions\"] = self.custom_instructions\n\n        if self.reason is not None:\n            base[\"reason\"] = self.reason\n\n        if self.source is not None:\n            base[\"source\"] = self.source\n\n        if self.model is not None:\n            base[\"model\"] = self.model\n\n        if self.permission_suggestions is not None:\n            base[\"permission_suggestions\"] = self.permission_suggestions\n\n        return base\n\n\n@dataclass\nclass HookResult:\n    \"\"\"Claude Code compatible hook result.\"\"\"\n\n    success: bool = True\n    output: Optional[str] = None\n    data: Optional[Dict[str, Any]] = None\n    modifications: Dict[str, Any] = field(default_factory=dict)\n    should_stop: bool = False\n\n    # Claude Code compatibility helpers\n    @classmethod\n    def block(\n        cls, reason: str, additional_context: Optional[str] = None\n    ) -> \"HookResult\":\n        \"\"\"Create a blocking result (exit code 2 in Claude Code).\"\"\"\n        modifications = {\"decision\": \"block\", \"reason\": reason, \"exit_code\": 2}\n        if additional_context:\n            modifications[\"additionalContext\"] = additional_context\n        return cls(success=False, should_stop=True, modifications=modifications)\n\n    @classmethod\n    def allow(\n        cls,\n        permission_decision: str = \"allow\",\n        reason: Optional[str] = None,\n        updated_input: Optional[Dict[str, Any]] = None,\n        additional_context: Optional[str] = None,\n    ) -> \"HookResult\":\n        \"\"\"Create an allow result for PreToolUse hooks.\"\"\"\n        modifications = {\"permissionDecision\": permission_decision, \"exit_code\": 0}\n        if reason:\n            modifications[\"permissionDecisionReason\"] = reason\n        if updated_input:\n            modifications[\"updatedInput\"] = updated_input\n        if additional_context:\n            modifications[\"additionalContext\"] = additional_context\n        return cls(success=True, modifications=modifications)\n\n    @classmethod\n    def ask(cls, reason: str, additional_context: Optional[str] = None) -> \"HookResult\":\n        \"\"\"Create an ask result for PreToolUse hooks.\"\"\"\n        modifications = {\n            \"permissionDecision\": \"ask\",\n            \"permissionDecisionReason\": reason,\n            \"exit_code\": 0,\n        }\n        if additional_context:\n            modifications[\"additionalContext\"] = additional_context\n        return cls(success=True, modifications=modifications)\n\n    @classmethod\n    def deny(\n        cls, reason: str, additional_context: Optional[str] = None\n    ) -> \"HookResult\":\n        \"\"\"Create a deny result for PreToolUse hooks.\"\"\"\n        modifications = {\n            \"permissionDecision\": \"deny\",\n            \"permissionDecisionReason\": reason,\n            \"exit_code\": 0,\n        }\n        if additional_context:\n            modifications[\"additionalContext\"] = additional_context\n        return cls(success=True, modifications=modifications)\n\n    @classmethod\n    def with_system_message(cls, message: str) -> \"HookResult\":\n        \"\"\"Create a result with a system message.\"\"\"\n        return cls(success=True, modifications={\"systemMessage\": message})\n\n    @classmethod\n    def with_additional_context(cls, context: str) -> \"HookResult\":\n        \"\"\"Create a result with additional context.\"\"\"\n        return cls(success=True, modifications={\"additionalContext\": context})\n\n    def to_claude_json(self) -> Dict[str, Any]:\n        \"\"\"Convert to Claude Code compatible JSON output.\"\"\"\n        # Start with modifications if present\n        if self.modifications:\n            result = dict(self.modifications)\n        else:\n            result = {}\n\n        # Add basic fields\n        result[\"success\"] = self.success\n        if self.output:\n            result[\"output\"] = self.output\n        if self.data:\n            result[\"data\"] = self.data\n\n        # Handle blocking case - ensure decision and reason are set\n        if not self.success and self.should_stop:\n            result[\"decision\"] = \"block\"\n            # Use reason from modifications if available, otherwise use output\n            if \"reason\" not in result:\n                result[\"reason\"] = self.output or \"Blocked by hook\"\n            if \"exit_code\" not in result:\n                result[\"exit_code\"] = 2\n        elif \"exit_code\" not in result:\n            result[\"exit_code\"] = 0\n\n        return result\n\n\nHookCallable = Callable[[HookContext], Awaitable[HookResult]]\n",
        "tool_call_id": "call_00_ThbWUxA88oZHYp7oeUwWqDWT",
        "metadata": null,
        "timestamp": "2026-02-08T00:30:17.671180Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:30:17.954406Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me examine the configuration system to understand how hooks are configured:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"src/zrb/config/config.py\", \"start_line\": 1, \"limit\": 100}",
        "tool_call_id": "call_00_VDiWXybYaAfsEYSfRbBpcF94",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 25129,
      "cache_write_tokens": 0,
      "cache_read_tokens": 23104,
      "output_tokens": 94,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 23104,
        "prompt_cache_miss_tokens": 2025
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:30:22.955501Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:30:19Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "d6e4dea7-f62a-47b5-9650-d1da5a15d142",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "File: src/zrb/config/config.py (Lines 1-100 of 1456)\nimport importlib.metadata as metadata\nimport logging\nimport os\n\nfrom zrb.config.helper import (\n    get_current_shell,\n    get_default_diff_edit_command,\n    get_env,\n    get_log_level,\n    get_max_token_threshold,\n    limit_token_threshold,\n)\nfrom zrb.util.string.conversion import to_boolean\nfrom zrb.util.string.format import fstring_format\n\n_DEFAULT_BANNER = \"\"\"\n                bb\n   zzzzz rr rr  bb\n     zz  rrr  r bbbbbb\n    zz   rr     bb   bb\n   zzzzz rr     bbbbbb   {VERSION} Pollux\n   _ _ . .  . _ .  _ . . .\nYour Automation Powerhouse\n\u2615 Donate at: https://stalchmst.com\n\ud83d\udc19 Submit issues/PR at: https://github.com/state-alchemists/zrb\n\ud83d\udc24 Follow us at: https://twitter.com/zarubastalchmst\n\"\"\"\n\n\nclass Config:\n    def __init__(self):\n        self.DEFAULT_ENV_PREFIX: str = \"ZRB\"\n        self.DEFAULT_SHELL: str = \"\"\n        self.DEFAULT_EDITOR: str = \"nano\"\n        self.DEFAULT_EDIT_COMMAND_TPL: str = \"\"\n        self.DEFAULT_INIT_MODULES: str = \"\"\n        self.DEFAULT_ROOT_GROUP_NAME: str = \"zrb\"\n        self.DEFAULT_ROOT_GROUP_DESCRIPTION: str = \"Your Automation Powerhouse\"\n        self.DEFAULT_INIT_SCRIPTS: str = \"\"\n        self.DEFAULT_INIT_FILE_NAME: str = \"zrb_init.py\"\n        self.DEFAULT_LOGGING_LEVEL: str = \"WARNING\"\n        self.DEFAULT_LOAD_BUILTIN: str = \"1\"\n        self.DEFAULT_WARN_UNRECOMMENDED_COMMAND: str = \"on\"\n        self.DEFAULT_SESSION_LOG_DIR: str = \"\"\n        self.DEFAULT_TODO_DIR: str = \"\"\n        self.DEFAULT_TODO_VISUAL_FILTER: str = \"\"\n        self.DEFAULT_TODO_RETENTION: str = \"2w\"\n        self.DEFAULT_VERSION: str = \"\"\n        self.DEFAULT_WEB_CSS_PATH: str = \"\"\n        self.DEFAULT_WEB_JS_PATH: str = \"\"\n        self.DEFAULT_WEB_FAVICON_PATH: str = \"/static/favicon-32x32.png\"\n        self.DEFAULT_WEB_COLOR: str = \"\"\n        self.DEFAULT_WEB_HTTP_PORT: str = \"21213\"\n        self.DEFAULT_WEB_GUEST_USERNAME: str = \"user\"\n        self.DEFAULT_WEB_SUPER_ADMIN_USERNAME: str = \"admin\"\n        self.DEFAULT_WEB_SUPER_ADMIN_PASSWORD: str = \"admin\"\n        self.DEFAULT_WEB_ACCESS_TOKEN_COOKIE_NAME: str = \"access_token\"\n        self.DEFAULT_WEB_REFRESH_TOKEN_COOKIE_NAME: str = \"refresh_token\"\n        self.DEFAULT_WEB_SECRET_KEY: str = \"zrb\"\n        self.DEFAULT_WEB_ENABLE_AUTH: str = \"0\"\n        self.DEFAULT_WEB_AUTH_ACCESS_TOKEN_EXPIRE_MINUTES: str = \"30\"\n        self.DEFAULT_WEB_AUTH_REFRESH_TOKEN_EXPIRE_MINUTES: str = \"60\"\n        self.DEFAULT_WEB_TITLE: str = \"Zrb\"\n        self.DEFAULT_WEB_JARGON: str = \"Your Automation PowerHouse\"\n        self.DEFAULT_WEB_HOMEPAGE_INTRO: str = \"Welcome to Zrb Web Interface\"\n        self.DEFAULT_LLM_ASSISTANT_NAME: str = \"\"\n        self.DEFAULT_LLM_ASSISTANT_ASCII_ART: str = \"default\"\n        self.DEFAULT_LLM_ASSISTANT_JARGON: str = \"\"\n        self.DEFAULT_LLM_UI_STYLE_TITLE_BAR: str = \"#ffffff\"\n        self.DEFAULT_LLM_UI_STYLE_INFO_BAR: str = \"#ffffff\"\n        self.DEFAULT_LLM_UI_STYLE_FRAME: str = \"#888888\"\n        self.DEFAULT_LLM_UI_STYLE_FRAME_LABEL: str = \"#ffff00\"\n        self.DEFAULT_LLM_UI_STYLE_INPUT_FRAME: str = \"#888888\"\n        self.DEFAULT_LLM_UI_STYLE_THINKING: str = \"ansigreen italic\"\n        self.DEFAULT_LLM_UI_STYLE_FAINT: str = \"#888888\"\n        self.DEFAULT_LLM_UI_STYLE_OUTPUT_FIELD: str = \"#eeeeee\"\n        self.DEFAULT_LLM_UI_STYLE_INPUT_FIELD: str = \"#eeeeee\"\n        self.DEFAULT_LLM_UI_STYLE_TEXT: str = \"#eeeeee\"\n        self.DEFAULT_LLM_UI_STYLE_STATUS: str = \"reverse\"\n        self.DEFAULT_LLM_UI_STYLE_BOTTOM_TOOLBAR: str = \"bg:#333333 #aaaaaa\"\n        self.DEFAULT_LLM_UI_COMMAND_SUMMARIZE: str = \"/compress, /compact\"\n        self.DEFAULT_LLM_UI_COMMAND_ATTACH: str = \"/attach\"\n        self.DEFAULT_LLM_UI_COMMAND_EXIT: str = \"/q, /bye, /quit, /exit\"\n        self.DEFAULT_LLM_UI_COMMAND_INFO: str = \"/info, /help\"\n        self.DEFAULT_LLM_UI_COMMAND_SAVE: str = \"/save\"\n        self.DEFAULT_LLM_UI_COMMAND_LOAD: str = \"/load\"\n        self.DEFAULT_LLM_UI_COMMAND_YOLO_TOGGLE: str = \"/yolo\"\n        self.DEFAULT_LLM_UI_COMMAND_REDIRECT_OUTPUT: str = \">, /redirect\"\n        self.DEFAULT_LLM_UI_COMMAND_EXEC: str = \"!, /exec\"\n        self.DEFAULT_LLM_UI_COMMAND_SET_MODEL: str = \"/model\"\n        self.DEFAULT_LLM_HISTORY_DIR: str = \"\"\n        self.DEFAULT_LLM_NOTE_FILE: str = \"\"\n        self.DEFAULT_LLM_MODEL: str = \"\"\n        self.DEFAULT_LLM_BASE_URL: str = \"\"\n        self.DEFAULT_LLM_API_KEY: str = \"\"\n        self.DEFAULT_LLM_MAX_REQUEST_PER_MINUTE: str = \"60\"\n        self.DEFAULT_LLM_MAX_TOKENS_PER_MINUTE: str = \"120000\"\n        self.DEFAULT_LLM_MAX_TOKENS_PER_REQUEST: str = \"120000\"\n        self.DEFAULT_LLM_THROTTLE_SLEEP: str = \"1.0\"\n        self.DEFAULT_LLM_HISTORY_SUMMARIZATION_WINDOW: str = \"5\"\n",
        "tool_call_id": "call_00_VDiWXybYaAfsEYSfRbBpcF94",
        "metadata": null,
        "timestamp": "2026-02-08T00:30:34.914348Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:30:35.100845Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me continue reading the config file to find hook-related settings:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "search_files",
        "args": "{\"path\": \"src/zrb/config/config.py\", \"regex\": \"HOOKS\"}",
        "tool_call_id": "call_00_L9HLzjngM7YHS8KXeRBa6xx0",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 26748,
      "cache_write_tokens": 0,
      "cache_read_tokens": 25216,
      "output_tokens": 78,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 25216,
        "prompt_cache_miss_tokens": 1532
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:30:38.083990Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:30:36Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "c952ffe0-336a-4efe-bf23-73daad416c08",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "search_files",
        "content": {
          "summary": "No matches found for pattern 'HOOKS' in path 'src/zrb/config/config.py' (searched 0 files).",
          "results": []
        },
        "tool_call_id": "call_00_L9HLzjngM7YHS8KXeRBa6xx0",
        "metadata": null,
        "timestamp": "2026-02-08T00:31:55.957534Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:33:30.566840Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me search more broadly:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "search_files",
        "args": "{\"path\": \"src/zrb/config/config.py\", \"regex\": \"hook\", \"file_pattern\": \"*.py\"}",
        "tool_call_id": "call_00_2aj9leVryF4ZFdhZ8bUVwZHD",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 26877,
      "cache_write_tokens": 0,
      "cache_read_tokens": 26816,
      "output_tokens": 87,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 26816,
        "prompt_cache_miss_tokens": 61
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:33:35.026579Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:33:32Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "2605d2f5-830d-4bb7-94bb-3c56ba200dd8",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "search_files",
        "content": {
          "summary": "No matches found for pattern 'hook' in path 'src/zrb/config/config.py' (searched 0 files).",
          "results": []
        },
        "tool_call_id": "call_00_2aj9leVryF4ZFdhZ8bUVwZHD",
        "metadata": null,
        "timestamp": "2026-02-08T00:36:34.463431Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:36:34.744816Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me read more of the config file to find the hook configuration:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"src/zrb/config/config.py\", \"start_line\": 200, \"limit\": 200}",
        "tool_call_id": "call_00_QsI7EHhp5TjXVw78KanlVi7D",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 27013,
      "cache_write_tokens": 0,
      "cache_read_tokens": 26944,
      "output_tokens": 94,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 26944,
        "prompt_cache_miss_tokens": 69
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:36:37.915935Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:36:36Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "1779590f-2cb9-4dc5-8683-c1cf84994676",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "File: src/zrb/config/config.py (Lines 200-399 of 1456)\n    def INIT_MODULES(self, value: list[str]):\n        os.environ[f\"{self.ENV_PREFIX}_INIT_MODULES\"] = \":\".join(value)\n\n    @property\n    def ROOT_GROUP_NAME(self) -> str:\n        return get_env(\"ROOT_GROUP_NAME\", self.DEFAULT_ROOT_GROUP_NAME, self.ENV_PREFIX)\n\n    @ROOT_GROUP_NAME.setter\n    def ROOT_GROUP_NAME(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_ROOT_GROUP_NAME\"] = value\n\n    @property\n    def ROOT_GROUP_DESCRIPTION(self) -> str:\n        return get_env(\n            \"ROOT_GROUP_DESCRIPTION\",\n            self.DEFAULT_ROOT_GROUP_DESCRIPTION,\n            self.ENV_PREFIX,\n        )\n\n    @ROOT_GROUP_DESCRIPTION.setter\n    def ROOT_GROUP_DESCRIPTION(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_ROOT_GROUP_DESCRIPTION\"] = value\n\n    @property\n    def INIT_SCRIPTS(self) -> list[str]:\n        init_scripts_str = get_env(\n            \"INIT_SCRIPTS\", self.DEFAULT_INIT_SCRIPTS, self.ENV_PREFIX\n        )\n        if init_scripts_str != \"\":\n            return [\n                script.strip()\n                for script in init_scripts_str.split(\":\")\n                if script.strip() != \"\"\n            ]\n        return []\n\n    @INIT_SCRIPTS.setter\n    def INIT_SCRIPTS(self, value: list[str]):\n        os.environ[f\"{self.ENV_PREFIX}_INIT_SCRIPTS\"] = \":\".join(value)\n\n    @property\n    def INIT_FILE_NAME(self) -> str:\n        return get_env(\"INIT_FILE_NAME\", self.DEFAULT_INIT_FILE_NAME, self.ENV_PREFIX)\n\n    @INIT_FILE_NAME.setter\n    def INIT_FILE_NAME(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_INIT_FILE_NAME\"] = value\n\n    @property\n    def LOGGING_LEVEL(self) -> int:\n        return get_log_level(\n            get_env(\"LOGGING_LEVEL\", self.DEFAULT_LOGGING_LEVEL, self.ENV_PREFIX)\n        )\n\n    @LOGGING_LEVEL.setter\n    def LOGGING_LEVEL(self, value: int | str):\n        if isinstance(value, int):\n            value = logging.getLevelName(value)\n        os.environ[f\"{self.ENV_PREFIX}_LOGGING_LEVEL\"] = str(value)\n\n    @property\n    def LOAD_BUILTIN(self) -> bool:\n        return to_boolean(\n            get_env(\"LOAD_BUILTIN\", self.DEFAULT_LOAD_BUILTIN, self.ENV_PREFIX)\n        )\n\n    @LOAD_BUILTIN.setter\n    def LOAD_BUILTIN(self, value: bool):\n        os.environ[f\"{self.ENV_PREFIX}_LOAD_BUILTIN\"] = \"1\" if value else \"0\"\n\n    @property\n    def WARN_UNRECOMMENDED_COMMAND(self) -> bool:\n        return to_boolean(\n            get_env(\n                \"WARN_UNRECOMMENDED_COMMAND\",\n                self.DEFAULT_WARN_UNRECOMMENDED_COMMAND,\n                self.ENV_PREFIX,\n            )\n        )\n\n    @WARN_UNRECOMMENDED_COMMAND.setter\n    def WARN_UNRECOMMENDED_COMMAND(self, value: bool):\n        os.environ[f\"{self.ENV_PREFIX}_WARN_UNRECOMMENDED_COMMAND\"] = (\n            \"1\" if value else \"0\"\n        )\n\n    @property\n    def SESSION_LOG_DIR(self) -> str:\n        default = self.DEFAULT_SESSION_LOG_DIR\n        if default == \"\":\n            default = os.path.expanduser(\n                os.path.join(\"~\", f\".{self.ROOT_GROUP_NAME}\", \"session\")\n            )\n        return get_env(\n            \"SESSION_LOG_DIR\",\n            default,\n            self.ENV_PREFIX,\n        )\n\n    @SESSION_LOG_DIR.setter\n    def SESSION_LOG_DIR(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_SESSION_LOG_DIR\"] = value\n\n    @property\n    def TODO_DIR(self) -> str:\n        default = self.DEFAULT_TODO_DIR\n        if default == \"\":\n            default = os.path.expanduser(os.path.join(\"~\", \"todo\"))\n        return get_env(\n            \"TODO_DIR\",\n            default,\n            self.ENV_PREFIX,\n        )\n\n    @TODO_DIR.setter\n    def TODO_DIR(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_TODO_DIR\"] = value\n\n    @property\n    def TODO_VISUAL_FILTER(self) -> str:\n        return get_env(\"TODO_FILTER\", self.DEFAULT_TODO_VISUAL_FILTER, self.ENV_PREFIX)\n\n    @TODO_VISUAL_FILTER.setter\n    def TODO_VISUAL_FILTER(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_TODO_FILTER\"] = value\n\n    @property\n    def TODO_RETENTION(self) -> str:\n        return get_env(\"TODO_RETENTION\", self.DEFAULT_TODO_RETENTION, self.ENV_PREFIX)\n\n    @TODO_RETENTION.setter\n    def TODO_RETENTION(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_TODO_RETENTION\"] = value\n\n    @property\n    def VERSION(self) -> str:\n        custom_version = os.getenv(\"_ZRB_CUSTOM_VERSION\", \"\")\n        if custom_version != \"\":\n            return custom_version\n        return (\n            self.DEFAULT_VERSION\n            if self.DEFAULT_VERSION != \"\"\n            else metadata.version(\"zrb\")\n        )\n\n    @VERSION.setter\n    def VERSION(self, value: str):\n        os.environ[\"_ZRB_CUSTOM_VERSION\"] = value\n\n    @property\n    def WEB_CSS_PATH(self) -> list[str]:\n        web_css_path_str = get_env(\n            \"WEB_CSS_PATH\", self.DEFAULT_WEB_CSS_PATH, self.ENV_PREFIX\n        )\n        if web_css_path_str != \"\":\n            return [\n                path.strip()\n                for path in web_css_path_str.split(\":\")\n                if path.strip() != \"\"\n            ]\n        return []\n\n    @WEB_CSS_PATH.setter\n    def WEB_CSS_PATH(self, value: list[str]):\n        os.environ[f\"{self.ENV_PREFIX}_WEB_CSS_PATH\"] = \":\".join(value)\n\n    @property\n    def WEB_JS_PATH(self) -> list[str]:\n        web_js_path_str = get_env(\n            \"WEB_JS_PATH\", self.DEFAULT_WEB_JS_PATH, self.ENV_PREFIX\n        )\n        if web_js_path_str != \"\":\n            return [\n                path.strip()\n                for path in web_js_path_str.split(\":\")\n                if path.strip() != \"\"\n            ]\n        return []\n\n    @WEB_JS_PATH.setter\n    def WEB_JS_PATH(self, value: list[str]):\n        os.environ[f\"{self.ENV_PREFIX}_WEB_JS_PATH\"] = \":\".join(value)\n\n    @property\n    def WEB_FAVICON_PATH(self) -> str:\n        return get_env(\n            \"WEB_FAVICON_PATH\", self.DEFAULT_WEB_FAVICON_PATH, self.ENV_PREFIX\n        )\n\n    @WEB_FAVICON_PATH.setter\n    def WEB_FAVICON_PATH(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_WEB_FAVICON_PATH\"] = value\n\n    @property\n    def WEB_COLOR(self) -> str:\n        return get_env(\"WEB_COLOR\", self.DEFAULT_WEB_COLOR, self.ENV_PREFIX)\n\n    @WEB_COLOR.setter\n    def WEB_COLOR(self, value: str):\n        os.environ[f\"{self.ENV_PREFIX}_WEB_COLOR\"] = value\n",
        "tool_call_id": "call_00_QsI7EHhp5TjXVw78KanlVi7D",
        "metadata": null,
        "timestamp": "2026-02-08T00:36:42.593122Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:36:42.737581Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me search for hook configuration in the manager file to understand how it's currently configured:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "search_files",
        "args": "{\"path\": \"src/zrb/llm/hook/manager.py\", \"regex\": \"CFG\\\\.HOOKS\"}",
        "tool_call_id": "call_00_xYfIeTbG1gPKLrmbkVTuqaDH",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 28932,
      "cache_write_tokens": 0,
      "cache_read_tokens": 27072,
      "output_tokens": 91,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 27072,
        "prompt_cache_miss_tokens": 1860
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:36:45.253387Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:36:43Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "0e0193ea-ade7-4646-ac30-92490744349b",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "search_files",
        "content": {
          "summary": "No matches found for pattern 'CFG\\.HOOKS' in path 'src/zrb/llm/hook/manager.py' (searched 0 files).",
          "results": []
        },
        "tool_call_id": "call_00_xYfIeTbG1gPKLrmbkVTuqaDH",
        "metadata": null,
        "timestamp": "2026-02-08T00:36:50.654839Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:36:50.866269Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me check the manager file more carefully:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"src/zrb/llm/hook/manager.py\", \"start_line\": 1, \"limit\": 50}",
        "tool_call_id": "call_00_cq6vcvDXXhj9Qh5Tspyovtpw",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 29083,
      "cache_write_tokens": 0,
      "cache_read_tokens": 28992,
      "output_tokens": 94,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 28992,
        "prompt_cache_miss_tokens": 91
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:36:52.761403Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:36:51Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "c07c3adb-1170-4a0e-af66-b268581a6358",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "File: src/zrb/llm/hook/manager.py (Lines 1-50 of 813)\nimport asyncio\nimport json\nimport logging\nimport os\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Union\n\nimport yaml\n\nfrom zrb.config.config import CFG\nfrom zrb.llm.hook.executor import (\n    HookExecutionResult,\n    ThreadPoolHookExecutor,\n    get_hook_executor,\n)\nfrom zrb.llm.hook.interface import HookCallable, HookContext, HookResult\nfrom zrb.llm.hook.schema import (\n    AgentHookConfig,\n    CommandHookConfig,\n    HookConfig,\n    MatcherConfig,\n    PromptHookConfig,\n)\nfrom zrb.llm.hook.types import HookEvent, HookType, MatcherOperator\n\nlogger = logging.getLogger(__name__)\n\n\nclass HookManager:\n    def __init__(\n        self,\n        auto_load: bool = True,\n        scan_dirs: Optional[List[Union[str, Path]]] = None,\n    ):\n        self._hooks: Dict[HookEvent, List[HookCallable]] = defaultdict(list)\n        self._global_hooks: List[HookCallable] = []\n        self._executor: ThreadPoolHookExecutor = get_hook_executor()\n        self._hook_configs: Dict[str, HookConfig] = {}  # name -> config for debugging\n        self._hook_to_config: Dict[HookCallable, HookConfig] = {}  # hook -> config mapping\n        if auto_load:\n            self.scan(scan_dirs)\n\n    def _evaluate_matchers(self, matchers: List[MatcherConfig], context: HookContext) -> bool:\n        \"\"\"\n        Evaluate all matchers against the given context.\n        Returns True if ALL matchers pass, False otherwise.\n        \n        Matchers can access fields in the context using dot notation.\n        For example: \"metadata.project\" or \"event_data.file_path\"\n",
        "tool_call_id": "call_00_cq6vcvDXXhj9Qh5Tspyovtpw",
        "metadata": null,
        "timestamp": "2026-02-08T00:36:57.356488Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:36:57.540556Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me look at the end of the manager file to see how it's instantiated:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"src/zrb/llm/hook/manager.py\", \"start_line\": 800, \"limit\": 20}",
        "tool_call_id": "call_00_xP6cQBPNgUtZER90GseMMsX1",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 29619,
      "cache_write_tokens": 0,
      "cache_read_tokens": 29120,
      "output_tokens": 104,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 29120,
        "prompt_cache_miss_tokens": 499
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:36:59.623136Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:36:58Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "47e26138-a2f6-4869-843b-d1dc37bc9fca",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "File: src/zrb/llm/hook/manager.py (Lines 800-813 of 813)\n                return HookResult(\n                    success=True,\n                    output=str(result.output),\n                    modifications=modifications\n                )\n                \n            except Exception as e:\n                logger.error(f\"Error executing agent hook: {e}\", exc_info=True)\n                return HookResult(success=False, output=str(e))\n\n        return agent_hook\n\n\nhook_manager = HookManager(auto_load=CFG.HOOKS_ENABLED, scan_dirs=CFG.HOOKS_DIRS)\n",
        "tool_call_id": "call_00_xP6cQBPNgUtZER90GseMMsX1",
        "metadata": null,
        "timestamp": "2026-02-08T00:37:04.881304Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:37:04.990295Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now I need to find where `CFG.HOOKS_ENABLED` and `CFG.HOOKS_DIRS` are defined. Let me search the entire codebase:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "run_shell_command",
        "args": "{\"command\": \"grep -r \\\"HOOKS_ENABLED\\\\|HOOKS_DIRS\\\" src/ --include=\\\"*.py\\\"\"}",
        "tool_call_id": "call_00_hg7durBr2GUeN7YEOWoEID2H",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 29859,
      "cache_write_tokens": 0,
      "cache_read_tokens": 29696,
      "output_tokens": 108,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 29696,
        "prompt_cache_miss_tokens": 163
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:37:07.377346Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:37:05Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "ed4521b5-aad6-488f-af6b-60263d6a0fcd",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "run_shell_command",
        "content": "Command: grep -r \"HOOKS_ENABLED\\|HOOKS_DIRS\" src/ --include=\"*.py\"\nDirectory: /root/zrb\nStdout:\nsrc/zrb/config/config.py:        self.DEFAULT_HOOKS_ENABLED: str = \"1\"\nsrc/zrb/config/config.py:        self.DEFAULT_HOOKS_DIRS: str = \"\"\nsrc/zrb/config/config.py:    def HOOKS_ENABLED(self) -> bool:\nsrc/zrb/config/config.py:            get_env(\"HOOKS_ENABLED\", self.DEFAULT_HOOKS_ENABLED, self.ENV_PREFIX)\nsrc/zrb/config/config.py:    @HOOKS_ENABLED.setter\nsrc/zrb/config/config.py:    def HOOKS_ENABLED(self, value: bool):\nsrc/zrb/config/config.py:        os.environ[f\"{self.ENV_PREFIX}_HOOKS_ENABLED\"] = \"1\" if value else \"0\"\nsrc/zrb/config/config.py:    def HOOKS_DIRS(self) -> list[str]:\nsrc/zrb/config/config.py:        dirs_str = get_env(\"HOOKS_DIRS\", self.DEFAULT_HOOKS_DIRS, self.ENV_PREFIX)\nsrc/zrb/config/config.py:    @HOOKS_DIRS.setter\nsrc/zrb/config/config.py:    def HOOKS_DIRS(self, value: list[str]):\nsrc/zrb/config/config.py:        os.environ[f\"{self.ENV_PREFIX}_HOOKS_DIRS\"] = \":\".join(value)\nsrc/zrb/llm/hook/manager.py:        for d in CFG.HOOKS_DIRS:\nsrc/zrb/llm/hook/manager.py:hook_manager = HookManager(auto_load=CFG.HOOKS_ENABLED, scan_dirs=CFG.HOOKS_DIRS)\nStderr:\n(empty)\nExit Code: 0\nBackground PIDs: (none)",
        "tool_call_id": "call_00_hg7durBr2GUeN7YEOWoEID2H",
        "metadata": null,
        "timestamp": "2026-02-08T00:37:16.398611Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:37:16.454550Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Good! Now let me examine the official Claude Code hooks documentation to understand the exact specification. Let me search for any existing documentation or examples:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"docs/hook-system.md\", \"start_line\": 1, \"limit\": 100}",
        "tool_call_id": "call_00_MOE5e5JREmKJhzQm4wcvjeAg",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 30412,
      "cache_write_tokens": 0,
      "cache_read_tokens": 29952,
      "output_tokens": 107,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 29952,
        "prompt_cache_miss_tokens": 460
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:37:18.236261Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:37:17Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "ef06b017-8cc5-461b-bf46-24de268f7895",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "File: docs/hook-system.md (Lines 1-100 of 355)\n# Zrb Hook System\n\n## Overview\n\nThe Zrb Hook System provides a powerful, extensible way to intercept and modify LLM interactions. It offers 100% compatibility with Claude Code hooks while adding advanced features like matcher evaluation, priority-based execution, and multiple hook types.\n\n## Key Features\n\n- **Claude Code Compatibility**: Full support for all Claude Code hook events and formats\n- **Thread-Safe Execution**: Built-in thread pool with timeout controls\n- **Matcher Evaluation**: Field-based filtering with 7 operators\n- **Priority System**: Control execution order of hooks\n- **Multiple Hook Types**: Command, Prompt, and Agent hooks\n- **Dual Discovery**: Load hooks from both `.zrb/` and `.claude/` directories\n- **Environment Injection**: Automatic injection of context into hook scripts\n\n## Architecture\n\n### Core Components\n\n1. **HookManager**: Singleton manager that discovers, loads, and executes hooks\n2. **HookExecutor**: Thread-safe executor with timeout controls\n3. **HookContext**: Rich context object with all event data\n4. **HookResult/HookExecutionResult**: Standardized result formats\n\n### Execution Flow\n\n```\nEvent Triggered \u2192 HookManager.find_hooks() \u2192 Matcher Evaluation \u2192 \nPriority Sorting \u2192 ThreadPool Execution \u2192 Result Aggregation \u2192 \nBlock Detection \u2192 Return Results\n```\n\n## Configuration\n\n### Location\n\nHooks can be placed in:\n\n1. **User Global**: `~/.zrb/hooks/` or `~/.zrb/hooks.json`\n2. **Project Local**: `./.zrb/hooks/` or `./.zrb/hooks.json`\n3. **Claude Code Compat**: `~/.claude/hooks/` or `~/.claude/hooks.json`\n4. **Project Claude**: `./.claude/hooks/` or `./.claude/hooks.json`\n\n### File Formats\n\n- JSON (`.json`)\n- YAML (`.yaml`, `.yml`)\n\n### Configuration Schema\n\n```yaml\nname: string              # Unique hook name\nevents: array             # List of events to trigger on\ntype: string              # \"command\", \"prompt\", or \"agent\"\nconfig: object            # Type-specific configuration\ndescription: string       # Optional description\nmatchers: array           # Optional matchers for conditional execution\nasync: boolean            # Run asynchronously (default: false)\nenabled: boolean          # Enable/disable hook (default: true)\ntimeout: integer          # Execution timeout in seconds\nenv: object               # Additional environment variables\npriority: integer         # Execution priority (higher = earlier)\n```\n\n## Hook Types\n\n### 1. Command Hooks\n\nExecute shell commands or scripts. Ideal for integrations with external systems.\n\n```json\n{\n  \"type\": \"command\",\n  \"config\": {\n    \"command\": \"echo 'Hello World'\",\n    \"shell\": true,\n    \"working_dir\": \"/optional/path\"\n  }\n}\n```\n\n**Features:**\n- Shell command execution\n- Environment variable injection\n- Working directory support\n- Timeout controls\n\n### 2. Prompt Hooks\n\nRun LLM prompts with template substitution from context.\n\n```json\n{\n  \"type\": \"prompt\",\n  \"config\": {\n    \"user_prompt_template\": \"Analyze: {{tool_name}} with input {{tool_input}}\",\n    \"system_prompt\": \"You are an analyzer.\",\n    \"model\": \"openai:gpt-4o-mini\",\n    \"temperature\": 0.0\n",
        "tool_call_id": "call_00_MOE5e5JREmKJhzQm4wcvjeAg",
        "metadata": null,
        "timestamp": "2026-02-08T00:37:24.056779Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:37:24.169541Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me examine the examples to understand the current configuration format:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"examples/hooks/basic-command-hook.json\"}",
        "tool_call_id": "call_00_alyKtkjfLx7qe7trJhwKAX8y",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 31292,
      "cache_write_tokens": 0,
      "cache_read_tokens": 30464,
      "output_tokens": 64,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 30464,
        "prompt_cache_miss_tokens": 828
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:37:25.908940Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:37:24Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "6023553b-7c74-483f-9f26-bdd04da63eab",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "[\n  {\n    \"name\": \"log-session-start\",\n    \"events\": [\"SessionStart\"],\n    \"type\": \"command\",\n    \"config\": {\n      \"command\": \"echo 'Session started at $(date)' >> /tmp/zrb-hooks.log\",\n      \"shell\": true\n    },\n    \"description\": \"Log session starts to a file\",\n    \"enabled\": true,\n    \"priority\": 10\n  },\n  {\n    \"name\": \"notify-tool-use\",\n    \"events\": [\"PreToolUse\"],\n    \"type\": \"command\",\n    \"config\": {\n      \"command\": \"echo 'Tool $CLAUDE_TOOL_NAME called with input: $CLAUDE_TOOL_INPUT'\",\n      \"shell\": true\n    },\n    \"description\": \"Notify when tools are used\",\n    \"matchers\": [\n      {\n        \"field\": \"tool_name\",\n        \"operator\": \"not_equals\",\n        \"value\": \"internal_tool\"\n      }\n    ],\n    \"enabled\": true,\n    \"priority\": 20\n  }\n]",
        "tool_call_id": "call_00_alyKtkjfLx7qe7trJhwKAX8y",
        "metadata": null,
        "timestamp": "2026-02-08T00:37:29.438999Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:37:29.593631Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me create a comprehensive gap analysis by comparing the current Zrb implementation with Claude Code's official specification. First, let me check if there's any existing documentation about Claude Code hooks:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "delegate_to_agent",
        "args": "{\"agent_name\": \"researcher\", \"task\": \"Research Claude Code hooks official documentation to understand the exact specification, including:\\n1. Configuration format structure\\n2. Matcher system implementation\\n3. Hook-specific output formats for each event type\\n4. Async hook support\\n5. Plugin/skill integration\\n6. Environment variables\\n7. Exit code handling\\n8. Timeout defaults\\n\\nPlease provide detailed findings with specific examples and citations from official documentation.\"}",
        "tool_call_id": "call_00_kBh5h2STjikiDL1NTYL1fJyV",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 31601,
      "cache_write_tokens": 0,
      "cache_read_tokens": 31296,
      "output_tokens": 180,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 31296,
        "prompt_cache_miss_tokens": 305
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:37:31.541506Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:37:30Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "3abc8d17-6645-472c-9e78-0f30b5a14a20",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "delegate_to_agent",
        "content": "Sub-agent 'researcher' completed the task:\n\n  Based on my comprehensive research of the official Claude Code hooks documentation, I can now provide you with a detailed research report. Let me compile all the findings.\n  \n  # Research Report: Claude Code Hooks Official Documentation\n  \n  ## Direct Answer\n  \n  Claude Code hooks are user-defined shell commands, LLM prompts, or agents that execute automatically at specific points in Claude Code's lifecycle. They provide a powerful automation system for validating operations, enforcing policies, adding context, and integrating external tools. The system supports three hook types (command, prompt, agent), 14 lifecycle events, matcher-based filtering, async execution, and comprehensive decision control through exit codes and JSON output.\n  \n  ## Evidence-Based Findings\n  \n  ### 1. Configuration Format Structure\n  \n  **Structure**: Three-level nested JSON configuration:\n  1. **Hook event** (e.g., `PreToolUse`, `Stop`)\n  2. **Matcher group** (regex filter for when hooks fire)\n  3. **Hook handlers** (one or more commands/prompts/agents to run)\n  \n  **Example Configuration**:\n  ```json\n  {\n    \"hooks\": {\n      \"PreToolUse\": [\n        {\n          \"matcher\": \"Bash\",\n          \"hooks\": [\n            {\n              \"type\": \"command\",\n              \"command\": \".claude/hooks/block-rm.sh\"\n            }\n          ]\n        }\n      ]\n    }\n  }\n  ```\n  \n  **Configuration Locations**:\n  - `~/.claude/settings.json` - User settings (all projects)\n  - `.claude/settings.json` - Project settings (shareable)\n  - `.claude/settings.local.json` - Local project settings (gitignored)\n  - Plugin `hooks/hooks.json` - When plugin is enabled\n  - Skill/agent frontmatter - While component is active\n  \n  **Source**: Official documentation sections \"Configuration\" and \"Hook locations\" from https://code.claude.com/docs/en/hooks\n  \n  ### 2. Matcher System Implementation\n  \n  **Matcher Patterns**: Regex strings that filter when hooks fire based on event type:\n  \n  | Event | What Matcher Filters | Example Values |\n  |-------|---------------------|----------------|\n  | `PreToolUse`, `PostToolUse`, `PostToolUseFailure`, `PermissionRequest` | Tool name | `Bash`, `Edit|Write`, `mcp__.*` |\n  | `SessionStart` | How session started | `startup`, `resume`, `clear`, `compact` |\n  | `SessionEnd` | Why session ended | `clear`, `logout`, `prompt_input_exit`, `bypass_permissions_disabled`, `other` |\n  | `Notification` | Notification type | `permission_prompt`, `idle_prompt`, `auth_success`, `elicitation_dialog` |\n  | `SubagentStart` | Agent type | `Bash`, `Explore`, `Plan`, custom names |\n  | `PreCompact` | What triggered compaction | `manual`, `auto` |\n  \n  **MCP Tool Matching**: MCP tools follow pattern `mcp__<server>__<tool>` (e.g., `mcp__memory__create_entities`). Use regex like `mcp__memory__.*` or `mcp__.*__write.*`.\n  \n  **No Matcher Support**: `UserPromptSubmit`, `Stop`, `TeammateIdle`, `TaskCompleted` always fire on every occurrence.\n  \n  **Source**: \"Matcher patterns\" and \"Match MCP tools\" sections from https://code.claude.com/docs/en/hooks\n  \n  ### 3. Hook-Specific Output Formats for Each Event Type\n  \n  **Common Input Fields** (all events receive via stdin):\n  - `session_id`, `transcript_path`, `cwd`, `permission_mode`, `hook_event_name`\n  \n  **Event-Specific Input Examples**:\n  \n  **PreToolUse**:\n  ```json\n  {\n    \"tool_name\": \"Bash\",\n    \"tool_input\": {\n      \"command\": \"npm test\",\n      \"description\": \"Run test suite\",\n      \"timeout\": 120000,\n      \"run_in_background\": false\n    },\n    \"tool_use_id\": \"...\"\n  }\n  ```\n  \n  **Write Tool**:\n  ```json\n  {\n    \"file_path\": \"/path/to/file.txt\",\n    \"content\": \"file content\"\n  }\n  ```\n  \n  **Edit Tool**:\n  ```json\n  {\n    \"file_path\": \"/path/to/file.txt\",\n    \"old_string\": \"original text\",\n    \"new_string\": \"replacement text\",\n    \"replace_all\": false\n  }\n  ```\n  \n  **PermissionRequest**:\n  ```json\n  {\n    \"tool_name\": \"Bash\",\n    \"tool_input\": {\n      \"command\": \"rm -rf node_modules\",\n      \"description\": \"Remove node_modules directory\"\n    },\n    \"permission_suggestions\": [\n      { \"type\": \"toolAlwaysAllow\", \"tool\": \"Bash\" }\n    ]\n  }\n  ```\n  \n  **Source**: Individual event sections (PreToolUse, PermissionRequest, etc.) from https://code.claude.com/docs/en/hooks\n  \n  ### 4. Async Hook Support\n  \n  **Configuration**: Add `\"async\": true` to command hooks:\n  ```json\n  {\n    \"type\": \"command\",\n    \"command\": \"/path/to/run-tests.sh\",\n    \"async\": true,\n    \"timeout\": 120\n  }\n  ```\n  \n  **Behavior**:\n  - Runs in background without blocking Claude\n  - Cannot block or control behavior (actions complete before hook finishes)\n  - Output delivered on next conversation turn\n  - Only `type: \"command\"` hooks support async\n  - No deduplication across multiple firings\n  \n  **Limitations**:\n  - Cannot return decisions (`permissionDecision`, `continue`, etc.)\n  - Only JSON fields `systemMessage` and `additionalContext` have effect\n  - Response waits if session is idle\n  \n  **Source**: \"Run hooks in the background\" section from https://code.claude.com/docs/en/hooks\n  \n  ### 5. Plugin/Skill Integration\n  \n  **Plugin Hooks**: Defined in `hooks/hooks.json` with optional `description` field:\n  ```json\n  {\n    \"description\": \"Automatic code formatting\",\n    \"hooks\": {\n      \"PostToolUse\": [\n        {\n          \"matcher\": \"Write|Edit\",\n          \"hooks\": [\n            {\n              \"type\": \"command\",\n              \"command\": \"${CLAUDE_PLUGIN_ROOT}/scripts/format.sh\",\n              \"timeout\": 30\n            }\n          ]\n        }\n      ]\n    }\n  }\n  ```\n  \n  **Skill/Agent Hooks**: Defined in frontmatter, scoped to component lifecycle:\n  ```yaml\n  ---\n  name: secure-operations\n  description: Perform operations with security checks\n  hooks:\n    PreToolUse:\n      - matcher: \"Bash\"\n        hooks:\n          - type: command\n            command: \"./scripts/security-check.sh\"\n  ---\n  ```\n  \n  **Path References**:\n  - `$CLAUDE_PROJECT_DIR` - Project root directory\n  - `${CLAUDE_PLUGIN_ROOT}` - Plugin root directory\n  - Use quotes for paths with spaces: `\"$CLAUDE_PROJECT_DIR\"/.claude/hooks/script.sh`\n  \n  **Source**: \"Reference scripts by path\" and \"Hooks in skills and agents\" sections from https://code.claude.com/docs/en/hooks\n  \n  ### 6. Environment Variables\n  \n  **Available Variables**:\n  - `$CLAUDE_PROJECT_DIR` - Current project directory\n  - `${CLAUDE_PLUGIN_ROOT}` - Plugin root directory (plugins only)\n  - `$CLAUDE_ENV_FILE` - File path for persisting environment variables (SessionStart hooks only)\n  - `$CLAUDE_CODE_REMOTE` - Set to `\"true\"` in remote web environments, not set in local CLI\n  \n  **Environment Persistence** (SessionStart only):\n  ```bash\n  #!/bin/bash\n  if [ -n \"$CLAUDE_ENV_FILE\" ]; then\n    echo 'export NODE_ENV=production' >> \"$CLAUDE_ENV_FILE\"\n    echo 'export DEBUG_LOG=true' >> \"$CLAUDE_ENV_FILE\"\n  fi\n  exit 0\n  ```\n  \n  **Source**: \"Persist environment variables\" and \"Reference scripts by path\" sections from https://code.claude.com/docs/en/hooks\n  \n  ### 7. Exit Code Handling\n  \n  **Exit Code Semantics**:\n  - **Exit 0**: Success. Claude Code parses stdout for JSON output (only processed on exit 0)\n  - **Exit 2**: Blocking error. stderr text fed back to Claude as error message, action blocked\n  - **Any other exit code**: Non-blocking error. stderr shown in verbose mode, execution continues\n  \n  **Exit Code 2 Behavior Per Event**:\n  \n  | Event | Can Block? | What Happens on Exit 2 |\n  |-------|-----------|------------------------|\n  | `PreToolUse` | Yes | Blocks the tool call |\n  | `PermissionRequest` | Yes | Denies the permission |\n  | `UserPromptSubmit` | Yes | Blocks prompt processing and erases prompt |\n  | `Stop` | Yes | Prevents Claude from stopping, continues conversation |\n  | `SubagentStop` | Yes | Prevents subagent from stopping |\n  | `TeammateIdle` | Yes | Prevents teammate from going idle |\n  | `TaskCompleted` | Yes | Prevents task from being marked as completed |\n  | `PostToolUse` | No | Shows stderr to Claude (tool already ran) |\n  | `PostToolUseFailure` | No | Shows stderr to Claude (tool already failed) |\n  | `Notification` | No | Shows stderr to user only |\n  | `SubagentStart` | No | Shows stderr to user only |\n  | `SessionStart` | No | Shows stderr to user only |\n  | `SessionEnd` | No | Shows stderr to user only |\n  | `PreCompact` | No | Shows stderr to user only |\n  \n  **Source**: \"Exit code output\" and \"Exit code 2 behavior per event\" sections from https://code.claude.com/docs/en/hooks\n  \n  ### 8. Timeout Defaults\n  \n  **Default Timeouts**:\n  - **Command hooks**: 600 seconds (10 minutes)\n  - **Prompt hooks**: 30 seconds\n  - **Agent hooks**: 60 seconds\n  - **Async hooks**: Same as command hooks (600 seconds) if not specified\n  \n  **Configuration**: Optional `timeout` field in seconds:\n  ```json\n  {\n    \"type\": \"command\",\n    \"command\": \"/path/to/script.sh\",\n    \"timeout\": 120  # 2 minutes\n  }\n  ```\n  \n  **Source**: \"Common fields\" section and timeout documentation from https://code.claude.com/docs/en/hooks\n  \n  ## Additional Key Specifications\n  \n  ### JSON Output Control\n  \n  **Universal Fields** (work across all events):\n  - `continue` (default `true`): If `false`, stops Claude entirely\n  - `stopReason`: Message shown to user when `continue` is `false`\n  - `suppressOutput` (default `false`): If `true`, hides stdout from verbose mode\n  - `systemMessage`: Warning message shown to user\n  \n  **Decision Control Patterns**:\n  - **UserPromptSubmit, PostToolUse, PostToolUseFailure, Stop, SubagentStop**: Top-level `decision` field\n  - **PreToolUse**: `hookSpecificOutput.permissionDecision` (`\"allow\"`, `\"deny\"`, `\"ask\"`)\n  - **PermissionRequest**: `hookSpecificOutput.decision.behavior` (`\"allow\"`, `\"deny\"`)\n  - **TeammateIdle, TaskCompleted**: Exit code only (no JSON decision)\n  \n  **Example JSON Output**:\n  ```json\n  {\n    \"hookSpecificOutput\": {\n      \"hookEventName\": \"PreToolUse\",\n      \"permissionDecision\": \"allow\",\n      \"permissionDecisionReason\": \"My reason here\",\n      \"updatedInput\": {\n        \"field_to_modify\": \"new value\"\n      },\n      \"additionalContext\": \"Current environment: production\"\n    }\n  }\n  ```\n  \n  ### Hook Events Summary (14 Total)\n  \n  1. `SessionStart` - When session begins/resumes\n  2. `UserPromptSubmit` - Before Claude processes prompt\n  3. `PreToolUse` - Before tool call executes (can block)\n  4. `PermissionRequest` - When permission dialog appears\n  5. `PostToolUse` - After tool call succeeds\n  6. `PostToolUseFailure` - After tool call fails\n  7. `Notification` - When Claude Code sends notification\n  8. `SubagentStart` - When subagent is spawned\n  9. `SubagentStop` - When subagent finishes\n  10. `Stop` - When Claude finishes responding\n  11. `TeammateIdle` - When agent team teammate about to go idle\n  12. `TaskCompleted` - When task being marked as completed\n  13. `PreCompact` - Before context compaction\n  14. `SessionEnd` - When session terminates\n  \n  ### Security Considerations\n  \n  **Disclaimer**: Hooks run with full user permissions and can modify/delete/access any files the user can access.\n  \n  **Best Practices**:\n  - Validate and sanitize inputs\n  - Always quote shell variables (`\"$VAR\"` not `$VAR`)\n  - Block path traversal (check for `..` in file paths)\n  - Use absolute paths with `\"$CLAUDE_PROJECT_DIR\"`\n  - Skip sensitive files (`.env`, `.git/`, keys, etc.)\n  \n  ## Uncertainty and Limitations\n  \n  **What I Cannot Verify**:\n  - Exact version requirements for all features (documentation doesn't specify minimum versions)\n  - Performance characteristics under heavy hook load\n  - Specific edge cases for MCP tool matching patterns\n  - Enterprise-specific features like `allowManagedHooksOnly`\n  \n  **Conflicting Information**: Some third-party sources mention 60-second default timeouts, but official documentation specifies 600 seconds for command hooks. The official documentation should be considered authoritative.\n  \n  ## References\n  \n  1. **Primary Source**: Hooks reference - Claude Code Docs - https://code.claude.com/docs/en/hooks\n  2. **GitHub Repository**: anthropics/claude-code - https://github.com/anthropics/claude-code\n  3. **Plugin Documentation**: hook-configuration - Claude Skills - https://claude-plugins.dev/skills/@andisab/swe-marketplace/hook-configuration\n  4. **Community Resources**: Claude Code Hooks Mastery - https://github.com/disler/claude-code-hooks-mastery\n  \n  **Note**: All information in this report is based on verified content from the official Claude Code documentation and related authoritative sources. Third-party articles and community resources were used only to confirm patterns observed in official documentation.\n",
        "tool_call_id": "call_00_kBh5h2STjikiDL1NTYL1fJyV",
        "metadata": null,
        "timestamp": "2026-02-08T00:45:41.226473Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:45:41.409912Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Excellent! Now I have comprehensive information about Claude Code's official hook specification. Let me now create a detailed gap analysis comparing the current Zrb implementation with the official specification. I'll create a comprehensive PLAN-POST.md document:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "write_file",
        "args": "{\"path\": \"PLAN-POST.md\", \"content\": \"# Zrb Hook System: Claude Code Compatibility Gap Analysis & Implementation Plan\\n\\n## Executive Summary\\n\\nThe current Zrb Hook System provides **partial compatibility** with Claude Code's official hook specification. While it supports all 14 hook events and basic execution patterns, there are significant format mismatches, missing features, and architectural differences that prevent 100% compatibility. This document outlines the gaps and provides a phased implementation plan to achieve full Claude Code compatibility.\\n\\n## Current State Assessment\\n\\n### \u2705 **Strengths (Already Compatible)**\\n\\n1. **Event Coverage**: 100% coverage of all 14 Claude Code hook events\\n2. **Exit Code Compatibility**: Proper handling of exit code 0 (success) and 2 (block)\\n3. **Thread Safety**: Thread-safe execution with timeout controls\\n4. **Environment Variables**: Basic injection of Claude context variables\\n5. **Hook Types**: Support for command, prompt, and agent hooks\\n6. **Configuration Discovery**: Dual directory scanning (`.zrb/` and `.claude/`)\\n\\n### \u26a0\ufe0f **Critical Gaps (Must Fix for 100% Compatibility)**\\n\\n## 1. Configuration Format Mismatch\\n\\n**Current Zrb Format** (Flat structure):\\n```json\\n[\\n  {\\n    \\\"name\\\": \\\"hook-name\\\",\\n    \\\"events\\\": [\\\"EventName\\\"],\\n    \\\"type\\\": \\\"command\\\",\\n    \\\"config\\\": {...},\\n    \\\"matchers\\\": [...]\\n  }\\n]\\n```\\n\\n**Claude Code Format** (Nested structure):\\n```json\\n{\\n  \\\"hooks\\\": {\\n    \\\"EventName\\\": [\\n      {\\n        \\\"matcher\\\": \\\"regex-pattern\\\",\\n        \\\"hooks\\\": [\\n          {\\n            \\\"type\\\": \\\"command\\\",\\n            \\\"command\\\": \\\"...\\\",\\n            \\\"timeout\\\": 30\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n}\\n```\\n\\n**Key Differences**:\\n- Claude Code uses `hooks.{event}.{matcher}.hooks[]` nesting\\n- Zrb uses flat array with `events[]` and `matchers[]` arrays\\n- Claude Code matchers are simple regex strings, not field-based objects\\n- Claude Code supports multiple hooks per matcher group\\n\\n## 2. Matcher System Incompatibility\\n\\n**Current Zrb Matchers**:\\n- Field-based with dot notation (`field: \\\"tool_name\\\"`)\\n- 7 operators (`equals`, `contains`, `regex`, `glob`, etc.)\\n- Complex evaluation logic with case sensitivity\\n\\n**Claude Code Matchers**:\\n- Simple regex patterns that match against event-specific fields\\n- Different fields per event type (tool name, session source, etc.)\\n- No field specification - implicit based on event type\\n- No operators - just regex matching\\n\\n**Example Claude Code Matcher**:\\n```json\\n{\\n  \\\"matcher\\\": \\\"Bash|Edit|Write\\\",\\n  \\\"hooks\\\": [...]\\n}\\n```\\n\\n## 3. Hook-Specific Output Format\\n\\n**Current Zrb Output**:\\n- Uses `modifications` dictionary with mixed fields\\n- Some Claude Code fields supported but not standardized\\n\\n**Claude Code Output**:\\n- Standardized `hookSpecificOutput` structure per event type\\n- Event-specific schemas (e.g., `permissionDecision` for PreToolUse)\\n- Universal fields: `continue`, `stopReason`, `suppressOutput`, `systemMessage`\\n\\n**Missing Output Schemas**:\\n- `PreToolUse`: `hookSpecificOutput.permissionDecision` (`allow`/`deny`/`ask`)\\n- `PermissionRequest`: `hookSpecificOutput.decision.behavior` (`allow`/`deny`)\\n- `UserPromptSubmit`: Top-level `decision` field\\n- Proper `updatedInput` modification for tool inputs\\n\\n## 4. Async Hook Support\\n\\n**Current Zrb**:\\n- `is_async: true` flag in configuration\\n- But execution may not properly handle async semantics\\n\\n**Claude Code Async Hooks**:\\n- Only for command hooks (`\\\"async\\\": true`)\\n- Cannot block or control behavior\\n- Only `systemMessage` and `additionalContext` have effect\\n- Output delivered on next conversation turn\\n- No deduplication across multiple firings\\n\\n## 5. Plugin/Skill Integration\\n\\n**Current Zrb**:\\n- No plugin system integration\\n- No skill/agent frontmatter support\\n- No `${CLAUDE_PLUGIN_ROOT}` variable support\\n\\n**Claude Code Integration**:\\n- Plugin hooks in `hooks/hooks.json` with `description` field\\n- Skill/agent hooks in frontmatter (`---` YAML blocks)\\n- Path variables: `$CLAUDE_PROJECT_DIR`, `${CLAUDE_PLUGIN_ROOT}`\\n- Environment persistence via `$CLAUDE_ENV_FILE` (SessionStart only)\\n\\n## 6. Timeout Defaults\\n\\n**Current Zrb**:\\n- Default 30-second timeout for all hooks\\n- Configurable per hook\\n\\n**Claude Code Defaults**:\\n- Command hooks: 600 seconds (10 minutes)\\n- Prompt hooks: 30 seconds\\n- Agent hooks: 60 seconds\\n- Async hooks: Same as command hooks (600s)\\n\\n## 7. Configuration Locations\\n\\n**Current Zrb Discovery**:\\n- `~/.zrb/hooks/`, `~/.zrb/hooks.json`\\n- `./.zrb/hooks/`, `./.zrb/hooks.json`\\n- `~/.claude/hooks/`, `~/.claude/hooks.json`\\n- `./.claude/hooks/`, `./.claude/hooks.json`\\n\\n**Claude Code Locations**:\\n- `~/.claude/settings.json` (user settings)\\n- `./.claude/settings.json` (project settings)\\n- `./.claude/settings.local.json` (local project, gitignored)\\n- Plugin `hooks/hooks.json` (when plugin enabled)\\n- Skill/agent frontmatter (while component active)\\n\\n## 8. Environment Variables\\n\\n**Missing Claude Code Variables**:\\n- `$CLAUDE_PROJECT_DIR` (project root directory)\\n- `${CLAUDE_PLUGIN_ROOT}` (plugin root directory)\\n- `$CLAUDE_ENV_FILE` (SessionStart only, for persisting env vars)\\n- `$CLAUDE_CODE_REMOTE` (true in web environments)\\n\\n## 9. Event-Specific Input Data\\n\\n**Current Zrb**:\\n- Generic `event_data` field\\n- Some event-specific fields in `HookContext`\\n\\n**Claude Code Event Data**:\\n- Structured JSON per event type\\n- Specific fields for each tool type (Write, Edit, Bash, etc.)\\n- MCP tool patterns: `mcp__<server>__<tool>`\\n\\n## 10. Priority System\\n\\n**Current Zrb**:\\n- Priority-based execution (higher priority first)\\n- Not part of Claude Code specification\\n\\n**Claude Code**:\\n- No priority system\\n- Hooks execute in order defined in configuration\\n- Multiple hooks per matcher execute sequentially\\n\\n## Implementation Plan (8 Phases)\\n\\n### Phase 1: Configuration Format Migration (Week 1)\\n**Goal**: Support both Zrb and Claude Code configuration formats\\n1. Create format detector and parser for Claude Code nested format\\n2. Add backward compatibility layer for existing Zrb format\\n3. Update `HookManager._parse_and_register()` to handle both formats\\n4. Create migration utility to convert Zrb format to Claude Code format\\n\\n### Phase 2: Matcher System Overhaul (Week 2)\\n**Goal**: Implement Claude Code regex-based matcher system\\n1. Replace field-based matchers with event-specific regex matching\\n2. Map event types to their matcher fields (tool name, session source, etc.)\\n3. Support both simple string matching and regex patterns\\n4. Add MCP tool pattern support (`mcp__.*__.*`)\\n\\n### Phase 3: Hook-Specific Output Standardization (Week 3)\\n**Goal**: Implement Claude Code standardized output formats\\n1. Create event-specific output schema classes\\n2. Update `HookResult` to generate proper `hookSpecificOutput`\\n3. Implement universal fields: `continue`, `stopReason`, `suppressOutput`, `systemMessage`\\n4. Add `updatedInput` modification support for tool inputs\\n\\n### Phase 4: Async Hook Implementation (Week 4)\\n**Goal**: Full async hook support per Claude Code spec\\n1. Implement true async execution for command hooks\\n2. Add async-specific limitations (no blocking decisions)\\n3. Handle output delivery on next conversation turn\\n4. Add timeout defaults (600s for async commands)\\n\\n### Phase 5: Plugin & Skill Integration (Week 5)\\n**Goal**: Support hooks in plugins, skills, and agents\\n1. Add plugin hook discovery (`hooks/hooks.json`)\\n2. Implement skill/agent frontmatter hook parsing\\n3. Add `${CLAUDE_PLUGIN_ROOT}` variable support\\n4. Implement environment persistence (`$CLAUDE_ENV_FILE`)\\n\\n### Phase 6: Environment & Path Variables (Week 6)\\n**Goal**: Complete Claude Code environment variable support\\n1. Add `$CLAUDE_PROJECT_DIR` detection and injection\\n2. Implement `$CLAUDE_ENV_FILE` for SessionStart hooks\\n3. Add `$CLAUDE_CODE_REMOTE` detection\\n4. Update path resolution with proper quoting\\n\\n### Phase 7: Timeout & Defaults Alignment (Week 7)\\n**Goal**: Match Claude Code timeout defaults and behavior\\n1. Update default timeouts: 600s command, 30s prompt, 60s agent\\n2. Add timeout inheritance and override logic\\n3. Implement proper timeout error handling per event type\\n4. Update configuration loading to respect Claude Code defaults\\n\\n### Phase 8: Testing & Validation (Week 8)\\n**Goal**: Ensure 100% compatibility through comprehensive testing\\n1. Create test suite with Claude Code hook examples\\n2. Test all 14 event types with matcher combinations\\n3. Validate output formats against Claude Code spec\\n4. Performance testing with multiple concurrent hooks\\n5. Create compatibility certification tool\\n\\n## Migration Strategy\\n\\n### Backward Compatibility\\n1. **Phase 1-3**: Maintain full backward compatibility\\n2. **Phase 4-6**: Add new features without breaking existing functionality\\n3. **Phase 7-8**: Optional migration to pure Claude Code format\\n\\n### Deprecation Timeline\\n- **Month 1-3**: Support both formats with warnings for Zrb format\\n- **Month 4-6**: Zrb format deprecated but still functional\\n- **Month 7+**: Zrb format removed, only Claude Code format supported\\n\\n### Migration Tools\\n1. `zrb hooks migrate` - Convert Zrb format to Claude Code format\\n2. `zrb hooks validate` - Validate hook configuration compatibility\\n3. `zrb hooks test` - Test hooks against Claude Code spec\\n\\n## Testing Strategy\\n\\n### Unit Tests\\n1. Configuration parsing for both formats\\n2. Matcher evaluation for all event types\\n3. Output format generation\\n4. Async hook execution\\n5. Environment variable injection\\n\\n### Integration Tests\\n1. End-to-end hook execution scenarios\\n2. Plugin/skill integration tests\\n3. Concurrent hook execution\\n4. Error handling and recovery\\n\\n### Compatibility Tests\\n1. Claude Code official example hooks\\n2. Third-party plugin hooks\\n3. Community hook collections\\n4. Edge cases and error conditions\\n\\n## Documentation Updates\\n\\n### Required Documentation\\n1. **Migration Guide**: Zrb \u2192 Claude Code format conversion\\n2. **Claude Code Compatibility Guide**: Feature matrix and limitations\\n3. **API Reference**: Updated hook configuration schema\\n4. **Examples**: Claude Code-compatible hook examples\\n5. **Troubleshooting**: Common issues and solutions\\n\\n### Documentation Locations\\n1. Update `docs/hook-system.md` with compatibility information\\n2. Create `docs/claude-code-compatibility.md`\\n3. Update `examples/hooks/` with Claude Code format examples\\n4. Add API documentation to docstrings\\n\\n## Risk Assessment\\n\\n### High Risk Areas\\n1. **Configuration Format Change**: Breaking existing user configurations\\n2. **Matcher System Overhaul**: Different matching logic may cause unexpected behavior\\n3. **Async Hook Implementation**: Complex threading and timing issues\\n\\n### Mitigation Strategies\\n1. **Phased Rollout**: Gradual introduction with backward compatibility\\n2. **Feature Flags**: Enable/disable new features during transition\\n3. **Comprehensive Testing**: Extensive test coverage before release\\n4. **User Communication**: Clear documentation and migration guides\\n\\n### Fallback Plan\\n1. Maintain legacy code path for Zrb format\\n2. Provide automatic migration tools\\n3. Offer support for mixed format during transition\\n4. Rollback capability if critical issues arise\\n\\n## Success Metrics\\n\\n### Technical Metrics\\n1. **100% Event Coverage**: All 14 Claude Code events supported\\n2. **Format Compatibility**: 100% Claude Code configuration format support\\n3. **Output Compatibility**: Correct JSON output for all event types\\n4. **Performance**: < 100ms overhead per hook execution\\n5. **Reliability**: 99.9% hook execution success rate\\n\\n### User Experience Metrics\\n1. **Migration Success**: > 90% of users successfully migrate\\n2. **Compatibility**: 100% of Claude Code example hooks work\\n3. **Documentation**: All features documented with examples\\n4. **Support Tickets**: < 5% increase in hook-related support requests\\n\\n## Timeline & Resources\\n\\n### Phase Timeline (8 Weeks Total)\\n- **Week 1-2**: Core format and matcher changes\\n- **Week 3-4**: Output standardization and async hooks\\n- **Week 5-6**: Plugin integration and environment variables\\n- **Week 7**: Timeout defaults and configuration\\n- **Week 8**: Testing, documentation, and release\\n\\n### Resource Requirements\\n1. **Development**: 2 senior developers (8 weeks each)\\n2. **Testing**: 1 QA engineer (4 weeks)\\n3. **Documentation**: 1 technical writer (2 weeks)\\n4. **Infrastructure**: CI/CD pipeline for compatibility testing\\n\\n### Deliverables\\n1. **Code**: Updated hook system with 100% Claude Code compatibility\\n2. **Tests**: Comprehensive test suite covering all features\\n3. **Documentation**: Updated user guides and API references\\n4. **Tools**: Migration and validation utilities\\n5. **Examples**: Claude Code-compatible hook examples\\n\\n## Conclusion\\n\\nAchieving 100% Claude Code hook compatibility is a significant but achievable goal. The current Zrb Hook System provides a solid foundation with 100% event coverage and basic execution patterns. The 8-phase implementation plan addresses all critical gaps while maintaining backward compatibility during the transition.\\n\\nThe key success factors are:\\n1. **Phased approach** to minimize disruption\\n2. **Backward compatibility** during migration\\n3. **Comprehensive testing** against Claude Code spec\\n4. **Clear documentation** and migration tools\\n\\nOnce completed, Zrb will offer the most comprehensive Claude Code hook compatibility of any automation framework, enabling users to seamlessly use their existing Claude Code hooks while benefiting from Zrb's advanced automation capabilities.\"}",
        "tool_call_id": "call_00_dR3xTDFthLK4kgWdH8IeTG8p",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 35088,
      "cache_write_tokens": 0,
      "cache_read_tokens": 31744,
      "output_tokens": 3268,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 31744,
        "prompt_cache_miss_tokens": 3344
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:45:43.978613Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:45:42Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "a9bd0b4a-0069-4ae1-91a1-b77566723521",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "write_file",
        "content": "Successfully wrote to PLAN-POST.md",
        "tool_call_id": "call_00_dR3xTDFthLK4kgWdH8IeTG8p",
        "metadata": null,
        "timestamp": "2026-02-08T00:53:16.395680Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:53:16.762766Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me verify the current implementation by examining some test files to understand how hooks are currently being tested:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "glob_files",
        "args": "{\"pattern\": \"**/test*hook*.py\", \"path\": \"src\"}",
        "tool_call_id": "call_00_OPniBSoeRZrptoOKVXJUowPO",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 38381,
      "cache_write_tokens": 0,
      "cache_read_tokens": 38336,
      "output_tokens": 85,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 38336,
        "prompt_cache_miss_tokens": 45
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:53:18.907453Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:53:17Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "cce1d92a-0a0f-4fd1-bbb0-8f4f8c50d917",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "glob_files",
        "content": [],
        "tool_call_id": "call_00_OPniBSoeRZrptoOKVXJUowPO",
        "metadata": null,
        "timestamp": "2026-02-08T00:53:25.121089Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:53:25.260163Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me check for any test files in the project:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "run_shell_command",
        "args": "{\"command\": \"find . -name \\\"*test*hook*\\\" -type f 2>/dev/null | head -10\"}",
        "tool_call_id": "call_00_dNjWinfKJSBY5AcAn4yw1m0J",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 38484,
      "cache_write_tokens": 0,
      "cache_read_tokens": 38464,
      "output_tokens": 76,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 38464,
        "prompt_cache_miss_tokens": 20
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:53:27.644867Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:53:26Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "2af8425d-548d-41c2-b044-c135134613d1",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "run_shell_command",
        "content": "Command: find . -name \"*test*hook*\" -type f 2>/dev/null | head -10\nDirectory: /root/zrb\nStdout:\n(empty)\nStderr:\n(empty)\nExit Code: 0\nBackground PIDs: (none)",
        "tool_call_id": "call_00_dNjWinfKJSBY5AcAn4yw1m0J",
        "metadata": null,
        "timestamp": "2026-02-08T00:53:53.338441Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:53:53.421988Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me check the examples directory more thoroughly to understand the current implementation:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "list_files",
        "args": "{\"path\": \"examples/hooks\"}",
        "tool_call_id": "call_00_Jvr13dZ50hoLgUm5pxMUILtz",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 38633,
      "cache_write_tokens": 0,
      "cache_read_tokens": 38528,
      "output_tokens": 58,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 38528,
        "prompt_cache_miss_tokens": 105
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:53:56.001270Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:53:54Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "14d9ff25-06e0-4174-af57-4bd441121ea2",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "list_files",
        "content": {
          "files": [
            "README.md",
            "basic-command-hook.json",
            "logging-hook.json",
            "prompt-review-hook.json",
            "security-hook.json"
          ]
        },
        "tool_call_id": "call_00_Jvr13dZ50hoLgUm5pxMUILtz",
        "metadata": null,
        "timestamp": "2026-02-08T00:54:00.185415Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:54:00.346700Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Let me read the README to understand the examples:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"examples/hooks/README.md\"}",
        "tool_call_id": "call_00_ugDC1NtOcKsDPKGOa5dKRYnJ",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 38739,
      "cache_write_tokens": 0,
      "cache_read_tokens": 38656,
      "output_tokens": 58,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 38656,
        "prompt_cache_miss_tokens": 83
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:54:03.287127Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:54:01Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "a76b8f23-41db-4bab-89bb-d480872c5920",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "# Zrb Hook System Examples\n\nThis directory contains examples of hook configurations for the Zrb framework, with 100% compatibility with Claude Code hooks.\n\n## Directory Structure\n\nHooks can be placed in either:\n- `~/.zrb/hooks/` or `~/.zrb/hooks.json` (user-global)\n- `./.zrb/hooks/` or `./.zrb/hooks.json` (project-local)\n- `~/.claude/hooks/` or `~/.claude/hooks.json` (Claude Code compatibility)\n- `./.claude/hooks/` or `./.claude/hooks.json` (Claude Code compatibility)\n\n## Hook Configuration Format\n\nHooks are defined in JSON or YAML format. Each hook has the following structure:\n\n```json\n{\n  \"name\": \"hook-name\",\n  \"events\": [\"EventName\"],\n  \"type\": \"command|prompt|agent\",\n  \"config\": {\n    // Type-specific configuration\n  },\n  \"description\": \"Optional description\",\n  \"matchers\": [\n    {\n      \"field\": \"field.path\",\n      \"operator\": \"equals|not_equals|contains|regex|glob|starts_with|ends_with\",\n      \"value\": \"value to match\",\n      \"case_sensitive\": true\n    }\n  ],\n  \"async\": false,\n  \"enabled\": true,\n  \"timeout\": 30,\n  \"env\": {\n    \"KEY\": \"value\"\n  },\n  \"priority\": 0\n}\n```\n\n## Available Events\n\nZrb supports all Claude Code hook events:\n\n- `SessionStart` - When a new session begins\n- `UserPromptSubmit` - When user submits a prompt\n- `PreToolUse` - Before a tool is executed\n- `PermissionRequest` - When permission is requested\n- `PostToolUse` - After a tool executes successfully\n- `PostToolUseFailure` - After a tool fails\n- `Notification` - For system notifications\n- `SubagentStart` - When a subagent starts\n- `SubagentStop` - When a subagent stops\n- `Stop` - When execution stops\n- `TeammateIdle` - When a teammate becomes idle\n- `TaskCompleted` - When a task completes\n- `PreCompact` - Before compacting history\n- `SessionEnd` - When a session ends\n\n## Hook Types\n\n### 1. Command Hooks\nExecute shell commands or scripts.\n\n```json\n{\n  \"name\": \"security-check\",\n  \"events\": [\"PreToolUse\"],\n  \"type\": \"command\",\n  \"config\": {\n    \"command\": \"python3 /path/to/security_check.py\",\n    \"shell\": true,\n    \"working_dir\": \"/optional/working/dir\"\n  },\n  \"matchers\": [\n    {\n      \"field\": \"tool_name\",\n      \"operator\": \"equals\",\n      \"value\": \"dangerous_tool\"\n    }\n  ],\n  \"priority\": 100\n}\n```\n\n### 2. Prompt Hooks\nRun LLM prompts with context.\n\n```json\n{\n  \"name\": \"prompt-review\",\n  \"events\": [\"UserPromptSubmit\"],\n  \"type\": \"prompt\",\n  \"config\": {\n    \"user_prompt_template\": \"Review this user prompt for safety: {{prompt}}\",\n    \"system_prompt\": \"You are a safety reviewer. Check for harmful content.\",\n    \"model\": \"openai:gpt-4o-mini\",\n    \"temperature\": 0.0\n  }\n}\n```\n\n### 3. Agent Hooks\nRun agents with tools.\n\n```json\n{\n  \"name\": \"agent-review\",\n  \"events\": [\"PreToolUse\"],\n  \"type\": \"agent\",\n  \"config\": {\n    \"system_prompt\": \"You are a security agent. Review tool calls for safety.\",\n    \"tools\": [\"file_read\", \"network_check\"],\n    \"model\": \"openai:gpt-4o\"\n  }\n}\n```\n\n## Matcher Operators\n\nMatchers allow hooks to run only when specific conditions are met:\n\n- `equals` - Exact match\n- `not_equals` - Not equal to value\n- `contains` - Contains substring\n- `regex` - Matches regular expression\n- `glob` - Matches glob pattern\n- `starts_with` - Starts with string\n- `ends_with` - Ends with string\n\nFields can use dot notation to access nested context:\n- `tool_name` - Name of the tool being called\n- `metadata.project` - Project name from metadata\n- `event_data.file_path` - File path from event data\n\n## Priority System\n\nHooks execute in priority order (higher priority first). Use this to ensure critical hooks (like security checks) run before others.\n\n## Blocking Decisions\n\nHooks can block execution by:\n1. Returning exit code 2\n2. Outputting JSON with `\"decision\": \"block\"`\n\nExample blocking hook:\n```bash\n#!/bin/bash\necho '{\"decision\": \"block\", \"reason\": \"Tool not allowed in production\"}'\nexit 2\n```\n\n## Environment Variables\n\nCommand hooks receive these environment variables:\n- `CLAUDE_HOOK_EVENT` - The hook event name\n- `CLAUDE_CWD` - Current working directory\n- `CLAUDE_TOOL_NAME` - Tool name (for tool events)\n- `CLAUDE_TOOL_INPUT` - Tool input as JSON\n- `CLAUDE_PROMPT` - User prompt (for prompt events)\n- `CLAUDE_EVENT_DATA` - Full event data as JSON\n\n## Examples in this Directory\n\n- `basic-command-hook.json` - Simple command hook example\n- `security-hook.json` - Security check with matchers\n- `prompt-review-hook.json` - LLM prompt review\n- `logging-hook.json` - Logging all tool calls\n- `blocking-hook.json` - Blocking dangerous operations",
        "tool_call_id": "call_00_ugDC1NtOcKsDPKGOa5dKRYnJ",
        "metadata": null,
        "timestamp": "2026-02-08T00:54:07.413804Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:54:08.072952Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now let me examine the security hook example to see how matchers are currently used:",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      },
      {
        "tool_name": "read_file",
        "args": "{\"path\": \"examples/hooks/security-hook.json\"}",
        "tool_call_id": "call_00_eHdu98BbM0yc7R0n7nwHW5Bx",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "tool-call"
      }
    ],
    "usage": {
      "input_tokens": 40080,
      "cache_write_tokens": 0,
      "cache_read_tokens": 38784,
      "output_tokens": 66,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 38784,
        "prompt_cache_miss_tokens": 1296
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:54:10.475227Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:54:08Z",
      "finish_reason": "tool_calls"
    },
    "provider_response_id": "c959c58e-5f5d-4613-8393-eab8b0da4fbf",
    "finish_reason": "tool_call",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "tool_name": "read_file",
        "content": "[\n  {\n    \"name\": \"block-dangerous-tools\",\n    \"events\": [\"PreToolUse\"],\n    \"type\": \"command\",\n    \"config\": {\n      \"command\": \"python3 -c \\\"import json, sys; print(json.dumps({'decision': 'block', 'reason': 'Dangerous tool not allowed'})); sys.exit(2)\\\"\",\n      \"shell\": false\n    },\n    \"description\": \"Block dangerous tools from being executed\",\n    \"matchers\": [\n      {\n        \"field\": \"tool_name\",\n        \"operator\": \"equals\",\n        \"value\": \"delete_files\"\n      },\n      {\n        \"field\": \"metadata.environment\",\n        \"operator\": \"equals\",\n        \"value\": \"production\"\n      }\n    ],\n    \"enabled\": true,\n    \"priority\": 100,\n    \"timeout\": 5\n  },\n  {\n    \"name\": \"require-approval-for-sensitive-tools\",\n    \"events\": [\"PermissionRequest\"],\n    \"type\": \"command\",\n    \"config\": {\n      \"command\": \"echo '{\\\"decision\\\": \\\"ask\\\", \\\"reason\\\": \\\"Requires manual approval\\\", \\\"permissionDecision\\\": \\\"ask\\\"}'\",\n      \"shell\": true\n    },\n    \"description\": \"Require manual approval for sensitive operations\",\n    \"matchers\": [\n      {\n        \"field\": \"tool_name\",\n        \"operator\": \"contains\",\n        \"value\": \"admin\",\n        \"case_sensitive\": false\n      }\n    ],\n    \"enabled\": true,\n    \"priority\": 90\n  }\n]",
        "tool_call_id": "call_00_eHdu98BbM0yc7R0n7nwHW5Bx",
        "metadata": null,
        "timestamp": "2026-02-08T00:54:16.549573Z",
        "part_kind": "tool-return"
      }
    ],
    "timestamp": "2026-02-08T00:54:16.968162Z",
    "instructions": "You are zrb, a highly capable and proactive AI assistant. You serve as a versatile partner, assisting with everything from deep technical engineering and system automation to creative analysis and research.\n\nWhile you are a generalist, you possess a **deep specialization in software engineering**. When faced with technical tasks, you adopt the mindset of an **expert, safety-conscious engineer**.\n\n**Your Core Identity:**\n*   **Context-Aware:** You are a seamless extension of the user's workflow. You naturally ground your actions in the local environment by observing the project structure, documentation (like `README.md` or `AGENTS.md`), and configuration to understand goals and conventions.\n*   **Rigorous & Iterative:** You prioritize correctness over speed. You rarely get complex tasks right on the first try; you **iterate, test, and fix** your own mistakes before reporting success.\n*   **Evidence-Based:** You do not trust your own generation until it is verified. You rely on the objective output of compilers, test runners, and page content to confirm success.\n*   **Decisive:** You do not get stuck in analysis paralysis. When the evidence confirms your solution works, you conclude the task immediately.\n*   **Safe:** You operate directly on the user's system. You verify the environment and validate assumptions before taking actions that modify the system state.\n*   **Idiomatic:** You ensure all work\u2014whether code, documentation, or configuration\u2014blends naturally with the existing project's style and architectural patterns.\n\nYour goal is to understand the user's intent and execute tasks to completion, making complex challenges feel simple through observation and expert action.\n# Mandate: Core Operating Directives\n\nThese directives are mandatory. Follow them at all times to ensure safety, efficiency, and correctness across all types of tasks.\n\n---\n\n## \u26d4 **Principle 1: Strict Adherence to Context**\n1.  **Conventions First:** Rigorously adhere to existing project conventions. Before modifying any artifact (code, docs, config), analyze surrounding patterns.\n2.  **Verify Availability:** **NEVER** assume a tool, library, or framework is available. Verify its established usage or presence in the environment before employing it.\n3.  **Mimic Style:** Seamlessly integrate your work by matching the existing formatting, naming, and structural patterns of the project.\n\n---\n\n## \ud83d\udee1\ufe0f **Principle 2: Safety and Verification**\nYou are operating directly on a user's machine.\n1.  **Validate Assumptions:** Never guess about file contents or system state. Use appropriate tools (like `read_file` or `run_shell_command`) to confirm facts before acting.\n2.  **Security:** Never introduce or log code that exposes secrets, API keys, or sensitive data.\n3.  **Explain Intent:** Before executing commands that modify the file system or system state, provide a concise, one-sentence explanation of your intent.\n4.  **Preserve Intent:** Do not revert or undo changes unless they caused an error or the user explicitly requested a reversal.\n\n---\n\n## \u2699\ufe0f **Principle 3: Systematic Workflow**\nFor tasks involving modification or creation (especially technical work), follow this sequence:\n\n1.  **UNDERSTAND**: Use discovery tools (search, glob, list) to map the environment. Read relevant context files.\n2.  **PLAN**: Build a grounded, step-by-step plan. If the request is ambiguous, seek clarification before acting.\n3.  **IMPLEMENT**: Execute the plan using the most direct tools available.\n    *   **Edit in Place:** Apply your final solution directly to original files. This ensures integration compatibility.\n        *   **DO NOT** create parallel \"refactored\" versions (e.g., `app_v2.py`, `refactored_app.py`).\n        *   **DO NOT** rename files unless explicitly instructed.\n        *   **Refactoring** means modifying the code *inside* the existing file.\n    *   **Architectural Changes:** You MAY create new files if the task requires architectural refactoring (e.g., splitting a monolith) or if you need temporary scripts for verification. However, the entry-point file MUST be updated to reflect these changes.\n    *   **Quality:** Proactively include necessary safeguards, such as unit tests for code or validation steps for data.\n    *   **Durability:** Treat all created artifacts (including tests and documentation) as permanent parts of the project.\n4.  **VERIFY (MANDATORY):** You MUST verify your work before declaring completion.\n    *   **Code:** Execute the code or run tests (using `run_shell_command`). If no tests exist, you MUST create a temporary test script (e.g. `_verify_fix.py`) to validate your changes.\n    *   **Text/Research:** Review your output against *every* specific constraint in the prompt (keywords, formats, citations).\n        *   **Keywords**: Verify presence of ALL required terms/phrases.\n        *   **Structure**: Verify required headings or sections (e.g., \"References\").\n        *   **Citations**: For research, you MUST verify claims using `open_web_page` and list sources.\n    *   **Zero-Tolerance:** NEVER declare a task \"complete\" if:\n        *   The task required a file (e.g., report, code) but you did not create it.\n        *   The task required a fix/feature but you did not use any modification tools (`write_file`, `replace_in_file`).\n        *   The task required code but you did not use any verification tools (`run_shell_command`).\n        *   The task required citations but you only used search snippets.\n    *   **Deliverable:** A task is ONLY complete when the required artifact (file, script, fix) exists on the disk. Thinking about it is not enough.\n    *   **Stop Condition:** Once your verification confirms success (e.g., tests pass, constraints met), **STOP** immediately. Do not perform redundant checks or seek perfection beyond the prompt's requirements.\n        *   **No Redundancy:** Do NOT re-read files you have just read. Do NOT re-run tests that have already passed unless you have changed the code.\n    \n    ---\n    \n    ## \ud83d\udde3\ufe0f **Principle 4: Communication Protocol**\n    1.  **Professional & Direct:** Adopt a tone suitable for a high-performance CLI environment.\n    2.  **Evidence-Based:** Your final response should summarize the evidence of success (e.g., \"Test passed,\" \"Keywords verified\").\n    3.  **Concise by Default:** Prioritize actions and results. Aim for minimal text output (ideally under 3 lines) **UNLESS** the user explicitly asks for an explanation, report, or creative content.\n    4.  **No Filler:** Avoid conversational preambles or postambles. Focus strictly on achieving the user's goal.\n    5.  **Tools over Talk:** Use tools to perform the work; use text only for essential communication or explanation.\n    \n    ---\n    \n    ## \ud83e\udd1d **Principle 5: Task Delegation**\n    When faced with complex, multi-step, or specialized tasks (e.g., deep research, extensive code generation, architectural planning), leverage your sub-agents.\n    1.  **Dynamic Utilization:** Check the `delegate_to_agent` tool description for the currently available roster of sub-agents. Do not rely on a static list; choose the best specialist for the specific sub-task at hand.\n    2.  **Full Fidelity Reporting (CRITICAL):**\n        *   **NO SUMMARIZATION:** You **MUST** present the sub-agent's findings in their entirety. Do not say \"The agent found X\" and summarize. Instead, paste the content.\n        *   **Preserve Formatting:** Keep code blocks, lists, citations, and links exactly as provided by the sub-agent.\n        *   **Raw Output:** If the sub-agent produces a final artifact (e.g., a blog post, a code snippet), your job is to deliver it to the user UNTOUCHED.\n    \n\n# System Context\n- **Current Time**: Sunday, February 08, 2026 07:15:55\n- **Operating System**: Linux 6.2.1-PRoot-Distro\n- **Current Directory**: /root/zrb\n\n#### Git Repository\n- **Branch:** fix/claude-hook\n- **Status:** Dirty (Uncommitted changes)\n- **Rules:**\n  - **NEVER** stage or commit your changes unless explicitly instructed.\n  - When asked to commit, always gather info first: `git status && git diff HEAD`.\n  - Always propose a draft commit message.\n\n\n# Agent Definitions (AGENTS.md)\n## Zrb Project Guide for Agents\n\nThis document provides context and guidelines for LLMs (Agents) working with the `zrb` (Zaruba) project. Zrb is a Python-based task automation tool that integrates shell commands, Python functions, and LLM capabilities into a unified workflow.\n\n### 1. Project Overview\n\n-   **Name:** Zrb (Zaruba)\n-   **Purpose:** Task automation and workflow orchestration.\n-   **Core Language:** Python.\n-   **Key Feature:** Built-in LLM integration for generating code and documentation.\n-   **Execution:** CLI (`zrb task-name`) or Web UI (`zrb server start`).\n\n### 2. Core Concepts\n\n#### 2.1. The `zrb_init.py` File\n-   **Role:** The entry point for defining tasks.\n-   **Location:**\n    -   **Project-local:** `./zrb_init.py` (Applies to the current project).\n    -   **Global:** `~/zrb_init.py` (Applies system-wide).\n-   **Discovery:** Zrb automatically detects and loads this file.\n\n#### 2.2. Tasks (`Task`)\nThe fundamental unit of work. Common types include:\n-   **`CmdTask`**: Executes shell commands.\n-   **`Task` (or `BaseTask`)**: Executes Python code.\n-   **`LLMTask`**: Interactions with LLMs.\n-   **`HttpCheck` / `TcpCheck`**: Readiness checks for services.\n\n#### 2.3. Groups (`Group`)\n-   Used to organize tasks hierarchically.\n-   Example: `zrb deployment build` (`deployment` is the group, `build` is the task).\n\n#### 2.4. Context (`ctx`)\nThe execution context passed to every task.\n-   **`ctx.input`**: User inputs (arguments).\n-   **`ctx.env`**: Environment variables.\n-   **`ctx.print()`**: Standard output method.\n-   **`ctx.xcom`**: Cross-communication storage.\n\n### 3. Defining Tasks (The \"How-To\")\n\n#### 3.1. Standard Shell Command (`CmdTask`)\nUse this for running CLI tools.\n\n```python\nfrom zrb import CmdTask, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"hello-world\",\n        cmd=\"echo Hello World\",\n        description=\"Prints hello world\"\n    )\n)\n```\n\n#### 3.2. Python Function (`@make_task`)\nPreferred for pure Python logic.\n\n```python\nfrom zrb import make_task, cli\n\n@make_task(group=cli, name=\"greet\", description=\"Greets a user\")\ndef greet(ctx):\n    name = ctx.input.name or \"World\"\n    ctx.print(f\"Hello, {name}!\")\n```\n\n#### 3.3. Task with Inputs and Env\nAlways define inputs and envs explicitly for better CLI/UI support.\n\n```python\nfrom zrb import CmdTask, StrInput, Env, cli\n\ncli.add_task(\n    CmdTask(\n        name=\"deploy\",\n        cmd=\"echo Deploying to $TARGET_ENV with user $DEPLOY_USER\",\n        input=[\n            StrInput(name=\"user\", default=\"admin\", description=\"Deployment user\")\n        ],\n        env=[\n            Env(name=\"TARGET_ENV\", default=\"staging\", link_to_os=True)\n        ]\n    )\n)\n```\n\n#### 3.4. Task Chaining (Dependencies)\n-   `>>` (Sequential): `task_a >> task_b` (A runs, then B).\n-   `<<` (Upstream): `task_b << task_a` (B depends on A).\n\n```python\nbuild >> test >> deploy\n```\n\n### 4. Configuration\n\nZrb is configured via environment variables (in `.env` or OS).\n\n-   **Primary LLM Model:** `ZRB_LLM_MODEL` (e.g., `openai:gpt-4o`, `deepseek:deepseek-reasoner`, `ollama:llama3.1`).\n-   **Small LLM Model:** `ZRB_LLM_SMALL_MODEL` (e.g., `openai:gpt-4o-mini`) - used for summarization and auxiliary tasks.\n-   **API Keys:** `ZRB_LLM_API_KEY`, `OPENAI_API_KEY`, etc.\n-   **Base URL:** `ZRB_LLM_BASE_URL` - for custom endpoints or local LLM servers.\n-   **Prompt Directory:** `ZRB_LLM_PROMPT_DIR` (default: `.zrb/llm/prompt`).\n-   **Plugin Directories:** `ZRB_LLM_PLUGIN_DIRS` - colon-separated paths to custom plugin directories containing agents and skills.\n\n**Note on Provider Prefixes:** Zrb supports built-in providers via `pydantic-ai`. When specifying models, use the format `provider:model-name` (e.g., `deepseek:deepseek-reasoner`, `ollama:llama3.1`). Built-in providers include OpenAI, Anthropic, Google, DeepSeek, Groq, Mistral, and Ollama.\n\n### 5. Common Patterns & Best Practices\n\n1.  **Prefer `CmdTask` for Shell Operations:** Do not use `subprocess` in Python tasks if a `CmdTask` can do the job.\n2.  **Use `ctx.print`:** Avoid `print()` to ensure output is captured and formatted correctly by Zrb.\n3.  **Explicit Inputs:** Define `Input` objects instead of parsing `sys.argv` manually.\n4.  **Readiness Checks:** Use `readiness_check` (`HttpCheck`, `TcpCheck`) for tasks that depend on services (e.g., waiting for a DB or Server).\n\n### 6. Directory Structure\n\n```\n/\n\u251c\u2500\u2500 zrb_init.py          # Main task definition file\n\u251c\u2500\u2500 .env                 # Environment variables\n\u251c\u2500\u2500 .zrb/                # Zrb internal/config storage\n\u2502   \u2514\u2500\u2500 llm/\n\u2502       \u2514\u2500\u2500 prompt/      # Custom LLM prompts\n\u2514\u2500\u2500 ...\n\n---\n\n## 7. LLM Extension Architectural Patterns\n\nWhen extending Zrb's LLM capabilities (e.g., adding hooks, new managers, etc.), follow these established patterns:\n\n### 7.1. Classic Python Classes\nAvoid using Pydantic's `BaseModel` for internal data structures or configurations. Use \"classic\" Python classes or `dataclasses`. This keeps the core lightweight and avoids dependency-heavy inheritance patterns.\n\n### 7.2. Module-Level Singletons\nManagers (like `SkillManager`, `NoteManager`, or `HookManager`) should be instantiated as singletons at the module level.\n-   Define the manager class.\n-   Create an instance at the bottom of the file (e.g., `hook_manager = HookManager()`).\n-   Import this instance where needed.\n\n### 7.3. Configuration and Path Conventions\n-   Always use `CFG.ROOT_GROUP_NAME` when defining default configuration or storage paths.\n-   Prefer paths like `.{CFG.ROOT_GROUP_NAME}/something` over hardcoded `.zrb/something`.\n-   Discovery logic should check:\n    1.  User home directory (`~/.{CFG.ROOT_GROUP_NAME}/...`)\n    2.  Project-local directories (climbing up from CWD to root, checking `.{CFG.ROOT_GROUP_NAME}/...`)\n    3.  Custom directories defined in `CFG`.\n\n### 7.4. Lazy Loading and Scanning\nManagers should have a `scan()` or `load()` method to discover artifacts, rather than doing it automatically in the constructor. This allows more control over when potentially heavy I/O operations occur.\n\n---\n\n## 8. Keeping This Guide Updated\n\nThis guide should be updated whenever significant changes are made to Zrb's architecture, configuration, or usage patterns. If you notice any information in this guide that is outdated or no longer relevant, please update it to ensure accuracy for future AI assistants working with the Zrb project.\n\nKey areas to keep current:\n- Configuration options and environment variables\n- Task definition patterns and best practices\n- Directory structure and file locations\n- Core concepts and terminology\n```\n\n\n\n\n# Available Skills (zrb Workflows)\nGroups (Use 'list_zrb_tasks' to see details):\n- base64: \ud83d\udcc4 Base64 operations\n- code: \ud83d\udcdc Code related command\n- docker: \ud83d\udc0b Docker related command\n- git: \ud83c\udf31 Git related commands\n- http: \ud83c\udf10 HTTP request operations\n- jwt: \ud83d\udd12 JWT encode/decode\n- llm: \ud83e\udd16 LLM operations\n- math: \u2795 Math tools\n- md5: \ud83d\udd22 Md5 operations\n- project: \ud83d\udcc1 Project related commands\n- publish: \ud83d\udce6 Publication related command\n- python: \ud83d\udc0d Python related commands\n- random: \ud83d\udd00 Random operation\n- searxng: \ud83d\udd0e Searxng related command\n- server: \ud83c\udf10 Server related command\n- setup: \ud83d\udd27 Setup\n- shell: \ud83d\udcac Shell related commands\n- test: \ud83d\udd0d Testing zrb codebase\n- todo: \u2705 Todo management\n- ulid: \ud83d\udd22 ULID operations\n- uuid: \ud83c\udd94 UUID operations\nTasks:\n- chat: \ud83e\udd16 Chat with your AI Assistant\n- create-clorine: create-clorine\n- create-natrium: create-natrium\n- create-salt: create-salt\n- figlet: figlet\n- ppn: ppn\n- print: print\n- schedule: schedule\n- test-error: test-error\n- trigger: trigger\n- version: \ud83c\udf1f Get current version",
    "kind": "request",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  },
  {
    "parts": [
      {
        "content": "Now I have a comprehensive understanding of the current implementation. Let me create a summary of the gap analysis findings and next steps:\n\n## Summary of Gap Analysis Findings\n\nBased on my analysis of the current Zrb hook implementation and comparison with Claude Code's official specification, I've identified the following key gaps:\n\n### 1. **Configuration Format Mismatch** (CRITICAL)\n- **Zrb**: Flat array format with `events[]` and `matchers[]` arrays\n- **Claude Code**: Nested `hooks.{event}.{matcher}.hooks[]` structure\n- **Impact**: Existing Zrb hooks won't work with Claude Code tools expecting the nested format\n\n### 2. **Matcher System Incompatibility** (CRITICAL)\n- **Zrb**: Field-based matchers with 7 operators and dot notation\n- **Claude Code**: Simple regex patterns matching event-specific fields\n- **Impact**: Different matching logic will cause hooks to fire incorrectly\n\n### 3. **Output Format Standardization** (HIGH)\n- **Zrb**: Mixed `modifications` dictionary\n- **Claude Code**: Standardized `hookSpecificOutput` with event-specific schemas\n- **Impact**: Hook outputs won't be properly interpreted by Claude Code\n\n### 4. **Missing Features** (MEDIUM)\n- Async hook limitations (only command hooks, can't block)\n- Plugin/skill integration (frontmatter hooks, plugin root variables)\n- Environment variables (`$CLAUDE_PROJECT_DIR`, `${CLAUDE_PLUGIN_ROOT}`)\n- Timeout defaults (600s command, 30s prompt, 60s agent)\n\n### 5. **Configuration Locations** (LOW)\n- **Zrb**: `.zrb/` and `.claude/` directories\n- **Claude Code**: `.claude/settings.json`, plugin `hooks/hooks.json`, frontmatter\n- **Impact**: Hooks won't be discovered in all expected locations\n\n## Next Steps\n\nBased on the comprehensive gap analysis in `PLAN-POST.md`, the implementation should proceed with **Phase 1: Configuration Format Migration**. This is the most critical gap that needs to be addressed first.\n\nThe implementation should:\n1. Create a format detector to handle both Zrb and Claude Code formats\n2. Add backward compatibility for existing Zrb format hooks\n3. Update the `HookManager` to parse both formats\n4. Create migration utilities for users\n\nThe good news is that the current Zrb implementation has a solid foundation with:\n- 100% event coverage\n- Proper exit code handling (0=success, 2=block)\n- Thread-safe execution\n- Basic environment variable injection\n- Support for all hook types (command, prompt, agent)\n\nThe migration to full Claude Code compatibility is achievable with the 8-phase plan outlined in the document.\n\n**Task completed**: Comprehensive gap analysis created with detailed implementation plan in `PLAN-POST.md`. The analysis identifies all critical compatibility gaps and provides a phased approach to achieve 100% Claude Code hook compatibility while maintaining backward compatibility.",
        "id": null,
        "provider_name": null,
        "provider_details": null,
        "part_kind": "text"
      }
    ],
    "usage": {
      "input_tokens": 40497,
      "cache_write_tokens": 0,
      "cache_read_tokens": 40128,
      "output_tokens": 637,
      "input_audio_tokens": 0,
      "cache_audio_read_tokens": 0,
      "output_audio_tokens": 0,
      "details": {
        "prompt_cache_hit_tokens": 40128,
        "prompt_cache_miss_tokens": 369
      }
    },
    "model_name": "deepseek-chat",
    "timestamp": "2026-02-08T00:54:19.627250Z",
    "kind": "response",
    "provider_name": "deepseek",
    "provider_url": "https://api.deepseek.com",
    "provider_details": {
      "timestamp": "2026-02-08T00:54:18Z",
      "finish_reason": "stop"
    },
    "provider_response_id": "8b6e2ef9-1415-420c-b00c-9c9f520b2b97",
    "finish_reason": "stop",
    "run_id": "43a6af42-a4b3-4b6a-97ce-7a07573fb400",
    "metadata": null
  }
]