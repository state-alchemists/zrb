# Findings on `zrb_ask` and `zrb_chat`

This document outlines the inner workings of `zrb_ask` and `zrb_chat`, focusing on prompt construction, tool calling, and the root cause of a `write_to_file` failure.

## `zrb_ask` and `zrb_chat` Implementation

- **Entry Point**: Both commands are initiated from `src/zrb/builtin/llm/llm_ask.py`.
  - `llm-ask` is an `LLMTask`.
  - `llm-chat` is a `BaseTrigger` that likely wraps `LLMTask`.
- **Core Logic**: The central logic resides in `src/zrb/task/llm_task.py`, specifically within the `LLMTask` class. This class manages the entire LLM interaction lifecycle:
  - Loading conversation history.
  - Building system and user prompts.
  - Creating an AI agent using the `pydantic-ai` library.
  - Executing the agent.
  - Saving the updated conversation history.
- **Tools**: Tools are dynamically gathered, including built-in tools and tools from the project. This is handled by `_get_tool` and `_get_toolset` in `src/zrb/builtin/llm/llm_ask.py`.

## Prompt Construction

- The `get_system_and_user_prompt` method in `src/zrb/task/llm_task.py` is responsible for creating the prompts.
- It combines a base system prompt, user-defined "workflows" (loaded via `src/zrb/task/llm/workflow.py`), and the user's message.
- The final prompt structure is determined by `src/zrb/task/llm/prompt.py`.

## Tool Calling Mechanism

- `zrb` uses `pydantic-ai` to create an agent that can use tools.
- The tools are Python functions decorated with `pydantic-ai`'s `@tool` decorator.
- When the LLM decides to use a tool, it generates a JSON object corresponding to the tool's input model.

## `write_to_file` Failure Analysis

- **Symptom**: The `write_to_file` tool occasionally fails with an `Invalid JSON` error.
- **Evidence**: `instruction/tool-call.log` shows the tool call and the error: `Invalid JSON: EOF while parsing an object at line 1 column 8583`.
- **Function Signature**: The `write_to_file` function is defined as `def write_to_file(file: FileToWrite | list[FileToWrite])`. It expects a single argument named `file`.
- **Tool Call Payload**: The LLM generated the following payload, which correctly matches the function's signature:
  ```json
  {
    "file": {
      "path": "sql/insert_routes_data.sql",
      "content": "..."
    }
  }
  ```
- **Root Cause**: The error `Invalid JSON: EOF while parsing an object` indicates that the JSON string being parsed by the tool-calling library (`pydantic-ai`) is malformed or incomplete. This is **not** a structural issue with the JSON object's keys (the structure is correct). The problem lies within the very long, single-line `content` string generated by the LLM. It is highly probable that the string was either truncated or contained unescaped characters that broke the JSON format, causing the parser to fail before reaching the end of the object.

- **Conclusion**: The failure is caused by the LLM generating invalid string content for the `content` field, which in turn creates a malformed JSON string for the overall tool call. The structural format of the tool call (`{"file": ...}`) is correct, but the content itself is flawed.
